import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import zipfile
from PIL import Image, ImageDraw, ImageFilter
import io
import requests
import base64
import replicate

try:
    from streamlit_drawable_canvas import st_canvas
    CANVAS_AVAILABLE = True
except ImportError:
    CANVAS_AVAILABLE = False

# --- ë°°ê²½ ì œê±° í•¨ìˆ˜ (ì—ì§€ ìŠ¤ë¬´ë”© í¬í•¨) ---
def remove_background(image, target_color, tolerance, edge_smoothing=0):
    """ë°°ê²½ìƒ‰ì„ ì œê±°í•˜ê³  íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)
    lower_bound = np.array([max(c - tolerance, 0) for c in target_color])
    upper_bound = np.array([min(c + tolerance, 255) for c in target_color])
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
    mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
    mask_inv = cv2.bitwise_not(mask)

    if edge_smoothing > 0:
        blur_size = edge_smoothing * 2 + 1
        mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
        kernel = np.ones((3, 3), np.uint8)
        mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)

    image[:, :, 3] = mask_inv
    return image

# --- ë¡œê³ /ì›Œí„°ë§ˆí¬ ì˜ì—­ ì œê±° í•¨ìˆ˜ ---
def remove_logo_area(image, regions):
    """ì§€ì •ëœ ì˜ì—­ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)
    for region in regions:
        x, y, w, h = int(region['x']), int(region['y']), int(region['width']), int(region['height'])
        x = max(0, x)
        y = max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)
        if w > 0 and h > 0:
            image[y:y+h, x:x+w, 3] = 0
    return image

# --- ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í•¨ìˆ˜ ---
def resize_image(pil_img, target_width, target_height):
    """PIL ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
    if target_width > 0 and target_height > 0:
        return pil_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    return pil_img

# --- ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„± í•¨ìˆ˜ ---
def create_sprite_sheet(images, columns=0):
    """ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ë¡œ í•©ì¹¨"""
    if not images:
        return None

    width, height = images[0].size
    total_images = len(images)

    if columns <= 0:
        total_width = width * total_images
        sheet = Image.new("RGBA", (total_width, height))
        for idx, img in enumerate(images):
            sheet.paste(img, (idx * width, 0))
    else:
        rows = (total_images + columns - 1) // columns
        total_width = width * columns
        total_height = height * rows
        sheet = Image.new("RGBA", (total_width, total_height))
        for idx, img in enumerate(images):
            row = idx // columns
            col = idx % columns
            sheet.paste(img, (col * width, row * height))

    return sheet

# --- ì¢Œí‘œì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ ---
def get_color_at_position(image_rgb, x, y):
    """ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ì¢Œí‘œì˜ RGB ìƒ‰ìƒ ë°˜í™˜"""
    if 0 <= x < image_rgb.shape[1] and 0 <= y < image_rgb.shape[0]:
        r, g, b = image_rgb[y, x]
        return f"#{r:02x}{g:02x}{b:02x}"
    return "#000000"

# --- AI ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜ ---
def generate_video_from_image(image_file, api_token, video_length="25_frames_with_svd_xt", motion_bucket_id=127, fps=6):
    """Replicate APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ ìƒì„±"""
    os.environ["REPLICATE_API_TOKEN"] = api_token

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    image_bytes = image_file.getvalue()
    base64_image = base64.b64encode(image_bytes).decode('utf-8')

    # ì´ë¯¸ì§€ MIME íƒ€ì… ê²°ì •
    image_file.seek(0)
    header = image_file.read(8)
    image_file.seek(0)

    if header[:8] == b'\x89PNG\r\n\x1a\n':
        mime_type = "image/png"
    elif header[:2] == b'\xff\xd8':
        mime_type = "image/jpeg"
    else:
        mime_type = "image/png"

    data_uri = f"data:{mime_type};base64,{base64_image}"

    # Replicate API í˜¸ì¶œ
    output = replicate.run(
        "stability-ai/stable-video-diffusion:3f0457e4619daac51203dedb472816fd3af8d253968904295257f682fd7a95f9c",
        input={
            "input_image": data_uri,
            "video_length": video_length,
            "motion_bucket_id": motion_bucket_id,
            "fps": fps
        }
    )

    return output

# --- ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ---
def process_video_to_sprites(video_path, bg_color_rgb, tolerance, edge_smoothing,
                              frame_interval, max_frames, use_custom_size,
                              output_width, output_height, logo_regions=None):
    """ë¹„ë””ì˜¤ë¥¼ ìŠ¤í”„ë¼ì´íŠ¸ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    cap = cv2.VideoCapture(video_path)

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    processed_pil_images = []

    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0 and extracted_count < max_frames:
            if logo_regions:
                frame = remove_logo_area(frame, logo_regions)
                processed_cv = frame.copy()
                rgb_image = cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGB)
                lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
                upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
                mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
                mask_inv = cv2.bitwise_not(mask)

                if edge_smoothing > 0:
                    blur_size = edge_smoothing * 2 + 1
                    mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
                    kernel = np.ones((3, 3), np.uint8)
                    mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)

                processed_cv[:, :, 3] = cv2.bitwise_and(processed_cv[:, :, 3], mask_inv)
            else:
                processed_cv = remove_background(frame, bg_color_rgb, tolerance, edge_smoothing)

            processed_rgb = cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA)
            pil_img = Image.fromarray(processed_rgb)

            if use_custom_size:
                pil_img = resize_image(pil_img, output_width, output_height)

            processed_pil_images.append(pil_img)
            extracted_count += 1

        frame_idx += 1

        if extracted_count >= max_frames:
            break

    cap.release()
    return processed_pil_images, total_frames

# ===== UI ì„¤ì • =====
st.set_page_config(page_title="Sprite Maker + AI", layout="wide")

# ===== ì‚¬ì´ë“œë°”: API ì„¤ì • ë° ëª¨ë“œ ì„ íƒ =====
with st.sidebar:
    st.header("ğŸ® ìŠ¤í”„ë¼ì´íŠ¸ ë©”ì´ì»¤")

    # ëª¨ë“œ ì„ íƒ
    st.subheader("ğŸ“Œ ëª¨ë“œ ì„ íƒ")
    app_mode = st.radio(
        "ì‘ì—… ëª¨ë“œ",
        ["ğŸ“¹ ë¹„ë””ì˜¤ ì—…ë¡œë“œ", "ğŸ¤– AI ìƒì„± (ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤)"],
        key="app_mode"
    )

    st.markdown("---")

    # AI ëª¨ë“œì¼ ë•Œë§Œ API í‚¤ ì…ë ¥ í‘œì‹œ
    if "AI ìƒì„±" in app_mode:
        st.subheader("ğŸ”‘ Replicate API")
        api_token = st.text_input(
            "API Token",
            type="password",
            placeholder="r8_xxxx...",
            help="https://replicate.com/account/api-tokens ì—ì„œ ë°œê¸‰"
        )

        if not api_token:
            st.warning("âš ï¸ API Tokenì„ ì…ë ¥í•´ì£¼ì„¸ìš”")

        st.markdown("---")

        # AI ìƒì„± ì„¤ì •
        st.subheader("ğŸ¬ AI ë¹„ë””ì˜¤ ì„¤ì •")
        video_length = st.selectbox(
            "ë¹„ë””ì˜¤ ê¸¸ì´",
            ["14_frames_with_svd", "25_frames_with_svd_xt"],
            index=1,
            help="í”„ë ˆì„ ìˆ˜ ì„ íƒ"
        )

        motion_bucket_id = st.slider(
            "ëª¨ì…˜ ê°•ë„",
            1, 255, 127,
            help="ë†’ì„ìˆ˜ë¡ ì›€ì§ì„ì´ í¼"
        )

        ai_fps = st.slider(
            "AI ë¹„ë””ì˜¤ FPS",
            1, 30, 6,
            help="ìƒì„±ë  ë¹„ë””ì˜¤ì˜ FPS"
        )

    st.markdown("---")

    # ê³µí†µ ì„¤ì •
    st.subheader("âš™ï¸ ë³€í™˜ ì„¤ì •")

    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", "#000000")
    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100)
    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3)

    st.markdown("---")

    st.subheader("ğŸ“ ì¶œë ¥ ì„¤ì •")
    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •", value=False)
    if use_custom_size:
        col1, col2 = st.columns(2)
        with col1:
            output_width = st.number_input("ë„ˆë¹„", 1, 4096, 256)
        with col2:
            output_height = st.number_input("ë†’ì´", 1, 4096, 256)
    else:
        output_width = 0
        output_height = 0

    st.markdown("---")

    st.subheader("ğŸï¸ í”„ë ˆì„ ì¶”ì¶œ")
    frame_interval = st.number_input("ì¶”ì¶œ ê°„ê²©", 1, 30, 1)
    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, 500, 100)

    st.markdown("---")

    st.subheader("ğŸ¬ GIF ì†ë„")
    gif_speed = st.slider("ms/í”„ë ˆì„", 10, 500, 100, 10)

# ===== ë©”ì¸ ì˜ì—­ =====
st.header("ğŸ¦– ìŠ¤í”„ë¼ì´íŠ¸ ìƒì„±ê¸°")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'logo_regions' not in st.session_state:
    st.session_state.logo_regions = []
if 'picked_color' not in st.session_state:
    st.session_state.picked_color = "#000000"
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []

bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

# ===== ë¹„ë””ì˜¤ ì—…ë¡œë“œ ëª¨ë“œ =====
if "ë¹„ë””ì˜¤ ì—…ë¡œë“œ" in app_mode:
    st.subheader("ğŸ“¹ ë¹„ë””ì˜¤ ì—…ë¡œë“œ ëª¨ë“œ")

    uploaded_file = st.file_uploader(
        "ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (MP4/MOV/AVI)",
        type=["mp4", "mov", "avi"],
        key="video_uploader"
    )

    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_file.read())
        tfile.close()

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        ret, first_frame = cap.read()
        first_frame_rgb = None
        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

        cap.release()

        st.info(f"ğŸ“¹ ì˜ìƒ ì •ë³´: {original_width}x{original_height} | {total_frames}í”„ë ˆì„ | {original_fps:.1f}fps")

        if first_frame_rgb is not None:
            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(first_frame_rgb, caption="ì²« í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)
            with col2:
                st.markdown("### ì›Œí„°ë§ˆí¬ ì˜ì—­")
                if st.session_state.logo_regions:
                    for idx, region in enumerate(st.session_state.logo_regions):
                        st.text(f"#{idx+1}: ({region['x']:.0f}, {region['y']:.0f})")
                        if st.button("ì‚­ì œ", key=f"del_{idx}"):
                            st.session_state.logo_regions.pop(idx)
                            st.rerun()

        if st.button("âœ¨ ë³€í™˜ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘..."):
                final_width = output_width if use_custom_size else original_width
                final_height = output_height if use_custom_size else original_height

                processed_images, _ = process_video_to_sprites(
                    tfile.name, bg_color_rgb, tolerance, edge_smoothing,
                    frame_interval, max_frames, use_custom_size,
                    final_width, final_height, st.session_state.logo_regions
                )

                st.session_state.processed_images = processed_images
                st.session_state.gif_speed = gif_speed

            st.success(f"âœ… ë³€í™˜ ì™„ë£Œ! {len(processed_images)}ê°œ í”„ë ˆì„")

        os.unlink(tfile.name)

# ===== AI ìƒì„± ëª¨ë“œ =====
else:
    st.subheader("ğŸ¤– AI ìƒì„± ëª¨ë“œ (ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ â†’ ìŠ¤í”„ë¼ì´íŠ¸)")

    st.markdown("""
    **ì‚¬ìš©ë²•:**
    1. ì •ì  ì´ë¯¸ì§€(PNG/JPG) ì—…ë¡œë“œ
    2. AIê°€ ì´ë¯¸ì§€ë¥¼ ì• ë‹ˆë©”ì´ì…˜ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
    3. ìë™ìœ¼ë¡œ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±
    """)

    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (PNG/JPG)",
        type=["png", "jpg", "jpeg"],
        key="image_uploader"
    )

    if uploaded_image is not None:
        # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        image = Image.open(uploaded_image)
        col1, col2 = st.columns([1, 1])

        with col1:
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
            st.caption(f"í¬ê¸°: {image.width}x{image.height}")

        with col2:
            st.markdown("### AI ìƒì„± ì„¤ì • ìš”ì•½")
            st.write(f"- ë¹„ë””ì˜¤ ê¸¸ì´: {video_length if 'video_length' in dir() else '25_frames_with_svd_xt'}")
            st.write(f"- ëª¨ì…˜ ê°•ë„: {motion_bucket_id if 'motion_bucket_id' in dir() else 127}")
            st.write(f"- FPS: {ai_fps if 'ai_fps' in dir() else 6}")

        # API í† í° ì²´í¬
        if not api_token:
            st.error("âŒ ì‚¬ì´ë“œë°”ì—ì„œ Replicate API Tokenì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            if st.button("ğŸš€ AI ë¹„ë””ì˜¤ ìƒì„± & ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜", type="primary", use_container_width=True):

                # 1ë‹¨ê³„: AI ë¹„ë””ì˜¤ ìƒì„±
                with st.status("ğŸ¤– AI ë¹„ë””ì˜¤ ìƒì„± ì¤‘...", expanded=True) as status:
                    st.write("â³ Stable Video Diffusion ëª¨ë¸ ì‹¤í–‰ ì¤‘...")
                    st.write("   (ì•½ 2~5ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

                    try:
                        uploaded_image.seek(0)
                        video_url = generate_video_from_image(
                            uploaded_image,
                            api_token,
                            video_length=video_length,
                            motion_bucket_id=motion_bucket_id,
                            fps=ai_fps
                        )

                        st.write("âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
                        st.write(f"ğŸ“¥ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘...")

                        # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
                        response = requests.get(video_url)
                        video_temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                        video_temp.write(response.content)
                        video_temp.close()

                        status.update(label="âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete")

                    except Exception as e:
                        status.update(label="âŒ AI ìƒì„± ì‹¤íŒ¨", state="error")
                        st.error(f"ì˜¤ë¥˜: {str(e)}")
                        st.stop()

                # ìƒì„±ëœ ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸°
                st.subheader("ğŸ¬ ìƒì„±ëœ AI ë¹„ë””ì˜¤")
                st.video(video_temp.name)

                # 2ë‹¨ê³„: ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜
                with st.spinner("ğŸ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„± ì¤‘..."):
                    cap = cv2.VideoCapture(video_temp.name)
                    ai_video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    ai_video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    cap.release()

                    final_width = output_width if use_custom_size else ai_video_width
                    final_height = output_height if use_custom_size else ai_video_height

                    processed_images, total = process_video_to_sprites(
                        video_temp.name, bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        final_width, final_height, []
                    )

                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed

                os.unlink(video_temp.name)
                st.success(f"âœ… ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜ ì™„ë£Œ! {len(processed_images)}ê°œ í”„ë ˆì„")

# ===== ê²°ê³¼ í‘œì‹œ =====
if st.session_state.processed_images:
    processed_pil_images = st.session_state.processed_images
    current_gif_speed = st.session_state.get('gif_speed', 100)

    st.markdown("---")
    st.header("ğŸ“¦ ê²°ê³¼ë¬¼")

    tab1, tab2, tab3 = st.tabs(["ğŸ¬ GIF ë¯¸ë¦¬ë³´ê¸°", "ğŸ“¥ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸", "ğŸ–¼ï¸ í”„ë ˆì„ ì„ íƒ"])

    with tab1:
        gif_buffer = io.BytesIO()
        processed_pil_images[0].save(
            gif_buffer, format="GIF", save_all=True,
            append_images=processed_pil_images[1:],
            duration=current_gif_speed, loop=0, disposal=2, transparency=0
        )
        st.image(gif_buffer.getvalue(), caption="íˆ¬ëª… ë°°ê²½ GIF")
        st.caption("ğŸ’¡ ë°°ê²½ì´ ê²€ê²Œ ë³´ì´ë©´ ë‹¤í¬ëª¨ë“œ ë•Œë¬¸ì…ë‹ˆë‹¤.")

        st.download_button(
            "ğŸ¬ GIF ë‹¤ìš´ë¡œë“œ",
            gif_buffer.getvalue(),
            "animation.gif",
            "image/gif",
            use_container_width=True
        )

    with tab2:
        sheet_columns = st.number_input(
            "ì—´ ìˆ˜ (0=ê°€ë¡œ í•œ ì¤„)", 0, len(processed_pil_images), 0,
            key="sheet_cols"
        )

        sprite_sheet = create_sprite_sheet(processed_pil_images, sheet_columns)
        sheet_buffer = io.BytesIO()
        sprite_sheet.save(sheet_buffer, format="PNG")

        st.image(sprite_sheet, caption=f"ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ({sprite_sheet.width}x{sprite_sheet.height})")

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ğŸ“„ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸(.png)",
                sheet_buffer.getvalue(),
                "sprite_sheet.png",
                "image/png",
                use_container_width=True
            )
        with col2:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for idx, img in enumerate(processed_pil_images):
                    img_byte_arr = io.BytesIO()
                    img.save(img_byte_arr, format="PNG")
                    zf.writestr(f"frame_{idx:03d}.png", img_byte_arr.getvalue())

            st.download_button(
                "ğŸ“¦ ë‚±ê°œ í”„ë ˆì„(.zip)",
                zip_buffer.getvalue(),
                "frames.zip",
                "application/zip",
                use_container_width=True
            )

    with tab3:
        st.subheader("í”„ë ˆì„ ì„ íƒ")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì „ì²´ ì„ íƒ", use_container_width=True):
                st.session_state.selected_frames = list(range(len(processed_pil_images)))
                st.rerun()
        with col2:
            if st.button("âŒ ì „ì²´ í•´ì œ", use_container_width=True):
                st.session_state.selected_frames = []
                st.rerun()

        if 'selected_frames' not in st.session_state:
            st.session_state.selected_frames = list(range(len(processed_pil_images)))

        cols_per_row = 6
        total_images = len(processed_pil_images)

        for row_start in range(0, total_images, cols_per_row):
            cols = st.columns(cols_per_row)
            for col_idx, img_idx in enumerate(range(row_start, min(row_start + cols_per_row, total_images))):
                with cols[col_idx]:
                    is_selected = img_idx in st.session_state.selected_frames
                    if st.checkbox(f"#{img_idx+1}", value=is_selected, key=f"sel_{img_idx}"):
                        if img_idx not in st.session_state.selected_frames:
                            st.session_state.selected_frames.append(img_idx)
                            st.session_state.selected_frames.sort()
                    else:
                        if img_idx in st.session_state.selected_frames:
                            st.session_state.selected_frames.remove(img_idx)

                    thumb = processed_pil_images[img_idx].copy()
                    thumb.thumbnail((80, 80))
                    st.image(thumb)

        st.markdown("---")
        selected_indices = st.session_state.selected_frames
        st.info(f"ì„ íƒ: {len(selected_indices)}ê°œ")

        if selected_indices:
            selected_images = [processed_pil_images[i] for i in selected_indices]
            custom_columns = st.number_input(
                "ì»¤ìŠ¤í…€ ì‹œíŠ¸ ì—´ ìˆ˜", 0, len(selected_images), 0,
                key="custom_cols"
            )

            custom_sheet = create_sprite_sheet(selected_images, custom_columns)
            custom_buffer = io.BytesIO()
            custom_sheet.save(custom_buffer, format="PNG")

            st.image(custom_sheet, caption=f"ì„ íƒ í”„ë ˆì„ ì‹œíŠ¸ ({custom_sheet.width}x{custom_sheet.height})")
            st.download_button(
                "ğŸ“„ ì„ íƒ í”„ë ˆì„ ì‹œíŠ¸(.png)",
                custom_buffer.getvalue(),
                "custom_sprite_sheet.png",
                "image/png",
                use_container_width=True
            )
