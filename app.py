import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import zipfile
from PIL import Image, ImageDraw
import io
import requests
import base64
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ë¡œì»¬ ê°œë°œìš©)
load_dotenv()

# Replicate API í† í° (Streamlit Cloud secrets ìš°ì„ , ì—†ìœ¼ë©´ .env)
def get_api_token():
    """Streamlit Cloudì˜ st.secrets ë˜ëŠ” .envì—ì„œ API í† í° ë¡œë“œ"""
    # Streamlit Cloud secrets í™•ì¸
    try:
        if "REPLICATE_API_TOKEN" in st.secrets:
            return st.secrets["REPLICATE_API_TOKEN"]
    except Exception:
        pass
    # ë¡œì»¬ .env íŒŒì¼ í™•ì¸
    return os.getenv("REPLICATE_API_TOKEN", "")

REPLICATE_API_TOKEN = get_api_token()

# Replicate import (í† í°ì´ ìˆì„ ë•Œë§Œ)
try:
    import replicate
    REPLICATE_AVAILABLE = True
except ImportError:
    REPLICATE_AVAILABLE = False

# --- ë°°ê²½ ì œê±° í•¨ìˆ˜ ---
def remove_background(image, target_color, tolerance, edge_smoothing=0):
    """ë°°ê²½ìƒ‰ì„ ì œê±°í•˜ê³  íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)

    lower_bound = np.array([max(c - tolerance, 0) for c in target_color])
    upper_bound = np.array([min(c + tolerance, 255) for c in target_color])
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
    mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
    mask_inv = cv2.bitwise_not(mask)

    if edge_smoothing > 0:
        blur_size = edge_smoothing * 2 + 1
        mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
        kernel = np.ones((3, 3), np.uint8)
        mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)

    image[:, :, 3] = mask_inv
    return image

# --- ë¡œê³  ì˜ì—­ ì œê±° ---
def remove_logo_area(image, regions):
    """ì§€ì •ëœ ì˜ì—­ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)
    for region in regions:
        x, y, w, h = int(region['x']), int(region['y']), int(region['width']), int(region['height'])
        x, y = max(0, x), max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)
        if w > 0 and h > 0:
            image[y:y+h, x:x+w, 3] = 0
    return image

# --- ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ---
def resize_image(pil_img, target_width, target_height):
    if target_width > 0 and target_height > 0:
        return pil_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    return pil_img

# --- ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„± ---
def create_sprite_sheet(images, columns=0):
    if not images:
        return None
    width, height = images[0].size
    total_images = len(images)

    if columns <= 0:
        total_width = width * total_images
        sheet = Image.new("RGBA", (total_width, height))
        for idx, img in enumerate(images):
            sheet.paste(img, (idx * width, 0))
    else:
        rows = (total_images + columns - 1) // columns
        sheet = Image.new("RGBA", (width * columns, height * rows))
        for idx, img in enumerate(images):
            sheet.paste(img, ((idx % columns) * width, (idx // columns) * height))
    return sheet

# --- ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (ë¯¸ë¦¬ë³´ê¸°ìš©) ---
def process_single_frame(frame_rgb, bg_color_rgb, tolerance, edge_smoothing, logo_regions=None):
    frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)

    if logo_regions:
        frame_bgra = remove_logo_area(frame_bgr.copy(), logo_regions)
        rgb_image = cv2.cvtColor(frame_bgra, cv2.COLOR_BGRA2RGB)
        lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
        upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
        mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
        mask_inv = cv2.bitwise_not(mask)
        if edge_smoothing > 0:
            blur_size = edge_smoothing * 2 + 1
            mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
            kernel = np.ones((3, 3), np.uint8)
            mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
        frame_bgra[:, :, 3] = cv2.bitwise_and(frame_bgra[:, :, 3], mask_inv)
        processed_cv = frame_bgra
    else:
        processed_cv = remove_background(frame_bgr, bg_color_rgb, tolerance, edge_smoothing)

    return Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

# --- AI ë¹„ë””ì˜¤ ìƒì„± ---
def generate_video_from_image(image_file, api_token, prompt="", video_length="25_frames_with_svd_xt", motion_bucket_id=127, fps=6):
    """Replicate APIë¡œ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ ìƒì„±"""
    os.environ["REPLICATE_API_TOKEN"] = api_token

    image_bytes = image_file.getvalue()
    base64_image = base64.b64encode(image_bytes).decode('utf-8')

    image_file.seek(0)
    header = image_file.read(8)
    image_file.seek(0)

    mime_type = "image/png" if header[:8] == b'\x89PNG\r\n\x1a\n' else "image/jpeg"
    data_uri = f"data:{mime_type};base64,{base64_image}"

    # Stable Video Diffusion ì‚¬ìš©
    output = replicate.run(
        "stability-ai/stable-video-diffusion:3f0457e4619daac51203dedb472816fd3af8d253968904295257f682fd7a95f9c",
        input={
            "input_image": data_uri,
            "video_length": video_length,
            "motion_bucket_id": motion_bucket_id,
            "fps": fps
        }
    )

    return output

# --- ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ---
def process_video_to_sprites(video_path, bg_color_rgb, tolerance, edge_smoothing,
                              frame_interval, max_frames, use_custom_size,
                              output_width, output_height, logo_regions=None):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    processed_pil_images = []

    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0 and extracted_count < max_frames:
            if logo_regions:
                frame = remove_logo_area(frame, logo_regions)
                processed_cv = frame.copy()
                rgb_image = cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGB)
                lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
                upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
                mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
                mask_inv = cv2.bitwise_not(mask)
                if edge_smoothing > 0:
                    blur_size = edge_smoothing * 2 + 1
                    mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
                    kernel = np.ones((3, 3), np.uint8)
                    mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
                processed_cv[:, :, 3] = cv2.bitwise_and(processed_cv[:, :, 3], mask_inv)
            else:
                processed_cv = remove_background(frame, bg_color_rgb, tolerance, edge_smoothing)

            pil_img = Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

            if use_custom_size and output_width > 0 and output_height > 0:
                pil_img = resize_image(pil_img, output_width, output_height)

            processed_pil_images.append(pil_img)
            extracted_count += 1

        frame_idx += 1
        if extracted_count >= max_frames:
            break

    cap.release()
    return processed_pil_images, total_frames

# --- ì²´í¬ë¬´ëŠ¬ ë°°ê²½ ìƒì„± ---
def create_checker_background(width, height, checker_size=10):
    checker = Image.new('RGB', (width, height))
    for i in range(0, width, checker_size):
        for j in range(0, height, checker_size):
            color = (200, 200, 200) if (i // checker_size + j // checker_size) % 2 == 0 else (255, 255, 255)
            for x in range(i, min(i + checker_size, width)):
                for y in range(j, min(j + checker_size, height)):
                    checker.putpixel((x, y), color)
    return checker

# ===== UI ì„¤ì • =====
st.set_page_config(page_title="Sprite Maker + AI", layout="wide")
st.header("ğŸ¦– ìŠ¤í”„ë¼ì´íŠ¸ ìƒì„±ê¸°")

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
if 'current_step' not in st.session_state:
    st.session_state.current_step = 1
if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
if 'generated_video_path' not in st.session_state:
    st.session_state.generated_video_path = None
if 'video_frames' not in st.session_state:
    st.session_state.video_frames = None
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []
if 'logo_regions' not in st.session_state:
    st.session_state.logo_regions = []

# ===== ì‚¬ì´ë“œë°”: ëª¨ë“œ ì„ íƒ =====
with st.sidebar:
    st.subheader("ğŸ“Œ ì‘ì—… ëª¨ë“œ")
    app_mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ“¹ ë¹„ë””ì˜¤ ì—…ë¡œë“œ", "ğŸ¤– AI ìƒì„± (ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤)"],
        key="app_mode"
    )

    # API í† í° ìƒíƒœ í‘œì‹œ
    if "AI ìƒì„±" in app_mode:
        st.markdown("---")
        st.subheader("ğŸ”‘ API ìƒíƒœ")
        if REPLICATE_API_TOKEN:
            st.success("âœ… API í† í° ë¡œë“œë¨")
        else:
            st.error("âŒ API í† í° ì—†ìŒ")
            st.caption("Streamlit Cloud: Secretsì— ì„¤ì •")
            st.caption("ë¡œì»¬: `.env` íŒŒì¼ì— ì„¤ì •")

    st.markdown("---")
    st.caption("ğŸ“‹ í˜„ì¬ ë‹¨ê³„")
    if "AI ìƒì„±" in app_mode:
        steps = ["1ï¸âƒ£ ì´ë¯¸ì§€ ì—…ë¡œë“œ", "2ï¸âƒ£ AI ë¹„ë””ì˜¤ ìƒì„±", "3ï¸âƒ£ ë°°ê²½ ì„¤ì •", "4ï¸âƒ£ ê²°ê³¼ë¬¼"]
    else:
        steps = ["1ï¸âƒ£ ë¹„ë””ì˜¤ ì—…ë¡œë“œ", "2ï¸âƒ£ ë°°ê²½ ì„¤ì •", "3ï¸âƒ£ ê²°ê³¼ë¬¼"]

    for i, step in enumerate(steps, 1):
        if i < st.session_state.current_step:
            st.write(f"âœ… {step}")
        elif i == st.session_state.current_step:
            st.write(f"ğŸ‘‰ **{step}**")
        else:
            st.write(f"â¬œ {step}")

# ===== AI ìƒì„± ëª¨ë“œ =====
if "AI ìƒì„±" in app_mode:

    # ========== STEP 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ ==========
    st.subheader("ğŸ“¤ Step 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ")

    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ (PNG/JPG)",
        type=["png", "jpg", "jpeg"],
        key="ai_image_uploader"
    )

    if uploaded_image:
        st.session_state.uploaded_image = uploaded_image
        image = Image.open(uploaded_image)

        col1, col2 = st.columns([1, 2])
        with col1:
            st.image(image, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ({image.width}x{image.height})", width="stretch")

        with col2:
            st.success("âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ!")
            st.caption("ë‹¤ìŒ ë‹¨ê³„ì—ì„œ AIê°€ ì´ ì´ë¯¸ì§€ë¥¼ ì›€ì§ì´ëŠ” ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

        if st.session_state.current_step < 2:
            st.session_state.current_step = 2

    # ========== STEP 2: AI ë¹„ë””ì˜¤ ìƒì„± ==========
    if st.session_state.current_step >= 2 and st.session_state.uploaded_image:
        st.markdown("---")
        st.subheader("ğŸ¤– Step 2: AI ë¹„ë””ì˜¤ ìƒì„±")

        if not REPLICATE_API_TOKEN:
            st.error("âŒ Replicate API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.markdown("""
**Streamlit Cloud ë°°í¬:**
1. ì•± ëŒ€ì‹œë³´ë“œ â†’ Settings â†’ Secrets
2. ì•„ë˜ ë‚´ìš© ì¶”ê°€:
```toml
REPLICATE_API_TOKEN = "your_token_here"
```

**ë¡œì»¬ ì‹¤í–‰:**
- `.env` íŒŒì¼ì— `REPLICATE_API_TOKEN=your_token` ì¶”ê°€
            """)
            st.stop()

        # AI ìƒì„± ì˜µì…˜
        with st.expander("ğŸ¬ AI ìƒì„± ì˜µì…˜", expanded=True):
            ai_prompt = st.text_area(
                "í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)",
                placeholder="ì˜ˆ: gentle swaying motion, breathing animation, subtle movement...",
                help="ì›í•˜ëŠ” ì›€ì§ì„ì„ ì„¤ëª…í•˜ì„¸ìš”. (í˜„ì¬ SVD ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ ì˜í–¥ì´ ì œí•œì )"
            )

            col1, col2, col3 = st.columns(3)
            with col1:
                video_length = st.selectbox(
                    "ë¹„ë””ì˜¤ ê¸¸ì´",
                    ["14_frames_with_svd", "25_frames_with_svd_xt"],
                    index=1
                )
            with col2:
                motion_bucket_id = st.slider("ëª¨ì…˜ ê°•ë„", 1, 255, 127, help="ë†’ì„ìˆ˜ë¡ ì›€ì§ì„ í¼")
            with col3:
                ai_fps = st.slider("FPS", 1, 30, 6)

        # ì´ë¯¸ ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if st.session_state.generated_video_path and os.path.exists(st.session_state.generated_video_path):
            st.success("âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
            st.video(st.session_state.generated_video_path)

            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±í•˜ê¸°", width="stretch"):
                    st.session_state.generated_video_path = None
                    st.session_state.current_step = 2
                    st.rerun()
            with col2:
                if st.button("â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", width="stretch"):
                    st.session_state.current_step = 3
                    st.rerun()
        else:
            # AI ìƒì„± ë²„íŠ¼
            if st.button("ğŸš€ AI ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘", type="primary", width="stretch"):
                with st.status("ğŸ¤– AI ë¹„ë””ì˜¤ ìƒì„± ì¤‘...", expanded=True) as status:
                    st.write("â³ Stable Video Diffusion ì‹¤í–‰ ì¤‘...")
                    st.write("   ì•½ 2~5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.")

                    try:
                        st.session_state.uploaded_image.seek(0)
                        video_url = generate_video_from_image(
                            st.session_state.uploaded_image,
                            REPLICATE_API_TOKEN,
                            prompt=ai_prompt,
                            video_length=video_length,
                            motion_bucket_id=motion_bucket_id,
                            fps=ai_fps
                        )

                        st.write("âœ… ìƒì„± ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ì¤‘...")

                        response = requests.get(video_url)
                        video_temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                        video_temp.write(response.content)
                        video_temp.close()

                        st.session_state.generated_video_path = video_temp.name
                        status.update(label="âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete")
                        st.rerun()

                    except Exception as e:
                        status.update(label="âŒ ìƒì„± ì‹¤íŒ¨", state="error")
                        st.error(f"ì˜¤ë¥˜: {str(e)}")

    # ========== STEP 3: ë°°ê²½ ì œê±° ì„¤ì • ==========
    if st.session_state.current_step >= 3 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 3: ë°°ê²½ ì œê±° ì„¤ì •")

        # ë¹„ë””ì˜¤ì—ì„œ ì²« í”„ë ˆì„ ì¶”ì¶œ
        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„")

            # ë°°ê²½ ì œê±° ì˜µì…˜
            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", "#000000")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100)
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3)

            # ì¶œë ¥ ì„¤ì •
            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width)
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height)
                    else:
                        output_width, output_height = video_width, video_height

                with col2:
                    frame_interval = st.number_input("í”„ë ˆì„ ì¶”ì¶œ ê°„ê²©", 1, 30, 1)
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, total_frames, min(total_frames, 100))

                gif_speed = st.slider("GIF ì†ë„ (ms/í”„ë ˆì„)", 10, 500, 100)

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")
                st.caption("ğŸ”² ì²´í¬ë¬´ëŠ¬ = íˆ¬ëª… ì˜ì—­")

            # ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜ ë²„íŠ¼
            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, st.session_state.logo_regions
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 4
                    st.rerun()

# ===== ë¹„ë””ì˜¤ ì—…ë¡œë“œ ëª¨ë“œ =====
else:
    # ========== STEP 1: ë¹„ë””ì˜¤ ì—…ë¡œë“œ ==========
    st.subheader("ğŸ“¤ Step 1: ë¹„ë””ì˜¤ ì—…ë¡œë“œ")

    uploaded_video = st.file_uploader(
        "ë¹„ë””ì˜¤ íŒŒì¼ (MP4/MOV/AVI)",
        type=["mp4", "mov", "avi"],
        key="video_uploader"
    )

    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.close()
        st.session_state.generated_video_path = tfile.name

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„ | {video_fps:.1f}fps")

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
            st.image(first_frame_rgb, caption="ì²« í”„ë ˆì„", width="stretch")

        st.session_state.current_step = 2

    # ========== STEP 2: ë°°ê²½ ì„¤ì • ==========
    if st.session_state.current_step >= 2 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 2: ë°°ê²½ ì œê±° ì„¤ì •")

        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", "#000000", key="video_bg")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100, key="video_tol")
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3, key="video_edge")

            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •", key="video_custom")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width, key="video_w")
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height, key="video_h")
                    else:
                        output_width, output_height = video_width, video_height
                with col2:
                    frame_interval = st.number_input("ì¶”ì¶œ ê°„ê²©", 1, 30, 1, key="video_int")
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, total_frames, min(total_frames, 100), key="video_max")

                gif_speed = st.slider("GIF ì†ë„", 10, 500, 100, key="video_gif")

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")

            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch", key="video_convert"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, []
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 3
                    st.rerun()

# ===== ê²°ê³¼ë¬¼ í‘œì‹œ =====
if st.session_state.processed_images:
    st.markdown("---")
    st.header("ğŸ“¦ ê²°ê³¼ë¬¼")

    processed_pil_images = st.session_state.processed_images
    current_gif_speed = st.session_state.get('gif_speed', 100)

    tab1, tab2, tab3 = st.tabs(["ğŸ¬ GIF", "ğŸ“„ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸", "ğŸ–¼ï¸ í”„ë ˆì„ ì„ íƒ"])

    with tab1:
        gif_buffer = io.BytesIO()
        processed_pil_images[0].save(
            gif_buffer, format="GIF", save_all=True,
            append_images=processed_pil_images[1:],
            duration=current_gif_speed, loop=0, disposal=2, transparency=0
        )
        st.image(gif_buffer.getvalue(), caption="íˆ¬ëª… ë°°ê²½ GIF")
        st.download_button("ğŸ¬ GIF ë‹¤ìš´ë¡œë“œ", gif_buffer.getvalue(), "animation.gif", "image/gif", width="stretch")

    with tab2:
        sheet_cols = st.number_input("ì—´ ìˆ˜ (0=ê°€ë¡œ í•œ ì¤„)", 0, len(processed_pil_images), 0)
        sprite_sheet = create_sprite_sheet(processed_pil_images, sheet_cols)
        sheet_buffer = io.BytesIO()
        sprite_sheet.save(sheet_buffer, format="PNG")
        st.image(sprite_sheet, caption=f"ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ({sprite_sheet.width}x{sprite_sheet.height})")

        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“„ PNG ì €ì¥", sheet_buffer.getvalue(), "sprite_sheet.png", "image/png", width="stretch")
        with col2:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for idx, img in enumerate(processed_pil_images):
                    img_arr = io.BytesIO()
                    img.save(img_arr, format="PNG")
                    zf.writestr(f"frame_{idx:03d}.png", img_arr.getvalue())
            st.download_button("ğŸ“¦ ZIP ì €ì¥", zip_buffer.getvalue(), "frames.zip", "application/zip", width="stretch")

    with tab3:
        if 'selected_frames' not in st.session_state:
            st.session_state.selected_frames = list(range(len(processed_pil_images)))

        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì „ì²´ ì„ íƒ", width="stretch"):
                st.session_state.selected_frames = list(range(len(processed_pil_images)))
                st.rerun()
        with col2:
            if st.button("âŒ ì „ì²´ í•´ì œ", width="stretch"):
                st.session_state.selected_frames = []
                st.rerun()

        cols_per_row = 6
        for row_start in range(0, len(processed_pil_images), cols_per_row):
            cols = st.columns(cols_per_row)
            for col_idx, img_idx in enumerate(range(row_start, min(row_start + cols_per_row, len(processed_pil_images)))):
                with cols[col_idx]:
                    is_sel = img_idx in st.session_state.selected_frames
                    if st.checkbox(f"#{img_idx+1}", value=is_sel, key=f"sel_{img_idx}"):
                        if img_idx not in st.session_state.selected_frames:
                            st.session_state.selected_frames.append(img_idx)
                    else:
                        if img_idx in st.session_state.selected_frames:
                            st.session_state.selected_frames.remove(img_idx)
                    thumb = processed_pil_images[img_idx].copy()
                    thumb.thumbnail((80, 80))
                    st.image(thumb)

        if st.session_state.selected_frames:
            st.info(f"ì„ íƒ: {len(st.session_state.selected_frames)}ê°œ")
            selected_imgs = [processed_pil_images[i] for i in sorted(st.session_state.selected_frames)]
            custom_cols = st.number_input("ì—´ ìˆ˜", 0, len(selected_imgs), 0, key="custom_cols")
            custom_sheet = create_sprite_sheet(selected_imgs, custom_cols)
            custom_buf = io.BytesIO()
            custom_sheet.save(custom_buf, format="PNG")
            st.image(custom_sheet)
            st.download_button("ğŸ“„ ì„ íƒ í”„ë ˆì„ ì €ì¥", custom_buf.getvalue(), "custom_sheet.png", "image/png", width="stretch")

    # ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°
    st.markdown("---")
    if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°", width="stretch"):
        st.session_state.current_step = 1
        st.session_state.uploaded_image = None
        st.session_state.generated_video_path = None
        st.session_state.processed_images = []
        st.session_state.selected_frames = []
        st.rerun()
