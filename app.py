import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import zipfile
from PIL import Image, ImageDraw
import io
import requests
import base64
from dotenv import load_dotenv
from streamlit_drawable_canvas import st_canvas

# ============================================
# API í† í° ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
# ============================================

# 1. ë¡œì»¬ .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# 2. Streamlit Cloud secretsì—ì„œ í† í° ê°€ì ¸ì™€ì„œ os.environì— ê°•ì œ ì£¼ì…
try:
    if "REPLICATE_API_TOKEN" in st.secrets:
        os.environ["REPLICATE_API_TOKEN"] = st.secrets["REPLICATE_API_TOKEN"]
except FileNotFoundError:
    # secrets.toml íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° (ë¡œì»¬ í™˜ê²½)
    pass

# 3. ìµœì¢… í† í° ê°’ í™•ì¸
REPLICATE_API_TOKEN = os.environ.get("REPLICATE_API_TOKEN", "")

# Replicate import
try:
    import replicate
    REPLICATE_AVAILABLE = True
except ImportError:
    REPLICATE_AVAILABLE = False

# --- ë°°ê²½ ì œê±° í•¨ìˆ˜ ---
def remove_background(image, target_color, tolerance, edge_smoothing=0):
    """ë°°ê²½ìƒ‰ì„ ì œê±°í•˜ê³  íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)

    lower_bound = np.array([max(c - tolerance, 0) for c in target_color])
    upper_bound = np.array([min(c + tolerance, 255) for c in target_color])
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
    mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
    mask_inv = cv2.bitwise_not(mask)

    if edge_smoothing > 0:
        blur_size = edge_smoothing * 2 + 1
        mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
        kernel = np.ones((3, 3), np.uint8)
        mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)

    image[:, :, 3] = mask_inv
    return image

# --- ë¡œê³  ì˜ì—­ ì œê±° ---
def remove_logo_area(image, regions):
    """ì§€ì •ëœ ì˜ì—­ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)
    for region in regions:
        x, y, w, h = int(region['x']), int(region['y']), int(region['width']), int(region['height'])
        x, y = max(0, x), max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)
        if w > 0 and h > 0:
            image[y:y+h, x:x+w, 3] = 0
    return image

# --- ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ---
def resize_image(pil_img, target_width, target_height):
    if target_width > 0 and target_height > 0:
        return pil_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    return pil_img

# --- ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„± ---
def create_sprite_sheet(images, columns=0):
    if not images:
        return None
    width, height = images[0].size
    total_images = len(images)

    if columns <= 0:
        total_width = width * total_images
        sheet = Image.new("RGBA", (total_width, height))
        for idx, img in enumerate(images):
            sheet.paste(img, (idx * width, 0))
    else:
        rows = (total_images + columns - 1) // columns
        sheet = Image.new("RGBA", (width * columns, height * rows))
        for idx, img in enumerate(images):
            sheet.paste(img, ((idx % columns) * width, (idx // columns) * height))
    return sheet

# --- ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (ë¯¸ë¦¬ë³´ê¸°ìš©) ---
def process_single_frame(frame_rgb, bg_color_rgb, tolerance, edge_smoothing, logo_regions=None):
    frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)

    if logo_regions:
        frame_bgra = remove_logo_area(frame_bgr.copy(), logo_regions)
        rgb_image = cv2.cvtColor(frame_bgra, cv2.COLOR_BGRA2RGB)
        lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
        upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
        mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
        mask_inv = cv2.bitwise_not(mask)
        if edge_smoothing > 0:
            blur_size = edge_smoothing * 2 + 1
            mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
            kernel = np.ones((3, 3), np.uint8)
            mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
        frame_bgra[:, :, 3] = cv2.bitwise_and(frame_bgra[:, :, 3], mask_inv)
        processed_cv = frame_bgra
    else:
        processed_cv = remove_background(frame_bgr, bg_color_rgb, tolerance, edge_smoothing)

    return Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

# --- AI ë¹„ë””ì˜¤ ìƒì„± ---
def generate_video_from_image(image_file, api_token, prompt="", video_length="25_frames_with_svd_xt", motion_bucket_id=127, fps=6):
    """Replicate APIë¡œ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ ìƒì„±"""
    os.environ["REPLICATE_API_TOKEN"] = api_token

    image_bytes = image_file.getvalue()
    base64_image = base64.b64encode(image_bytes).decode('utf-8')

    image_file.seek(0)
    header = image_file.read(8)
    image_file.seek(0)

    mime_type = "image/png" if header[:8] == b'\x89PNG\r\n\x1a\n' else "image/jpeg"
    data_uri = f"data:{mime_type};base64,{base64_image}"

    # Stable Video Diffusion ì‚¬ìš©
    output = replicate.run(
        "stability-ai/stable-video-diffusion:3f0457e4619daac51203dedb472816fd4af51f3149fa7a9e0b5ffcf1b8172438",
        input={
            "input_image": data_uri,
            "video_length": video_length,
            "motion_bucket_id": motion_bucket_id,
            "fps": fps
        }
    )

    return output

# --- ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ---
def process_video_to_sprites(video_path, bg_color_rgb, tolerance, edge_smoothing,
                              frame_interval, max_frames, use_custom_size,
                              output_width, output_height, logo_regions=None,
                              skip_start_frames=0, skip_end_frames=0):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    processed_pil_images = []

    # íŠ¸ë¦¬ë° í›„ ìœ íš¨í•œ í”„ë ˆì„ ë²”ìœ„ ê³„ì‚°
    start_frame = skip_start_frames
    end_frame = max(start_frame + 1, total_frames - skip_end_frames)

    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # íŠ¸ë¦¬ë° ë²”ìœ„ ë‚´ì˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
        if frame_idx >= start_frame and frame_idx < end_frame:
            if (frame_idx - start_frame) % frame_interval == 0 and extracted_count < max_frames:
                if logo_regions:
                    frame = remove_logo_area(frame, logo_regions)
                    processed_cv = frame.copy()
                    rgb_image = cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGB)
                    lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
                    upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
                    mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
                    mask_inv = cv2.bitwise_not(mask)
                    if edge_smoothing > 0:
                        blur_size = edge_smoothing * 2 + 1
                        mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
                        kernel = np.ones((3, 3), np.uint8)
                        mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
                    processed_cv[:, :, 3] = cv2.bitwise_and(processed_cv[:, :, 3], mask_inv)
                else:
                    processed_cv = remove_background(frame, bg_color_rgb, tolerance, edge_smoothing)

                pil_img = Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

                if use_custom_size and output_width > 0 and output_height > 0:
                    pil_img = resize_image(pil_img, output_width, output_height)

                processed_pil_images.append(pil_img)
                extracted_count += 1

        frame_idx += 1
        if extracted_count >= max_frames:
            break

    cap.release()
    return processed_pil_images, total_frames

# --- ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ (ìŠ¤í¬ì´ë“œ) ---
def get_color_at_position(image_rgb, x, y):
    """ì´ë¯¸ì§€ì˜ íŠ¹ì • ì¢Œí‘œì—ì„œ RGB ìƒ‰ìƒ ì¶”ì¶œ"""
    if 0 <= x < image_rgb.shape[1] and 0 <= y < image_rgb.shape[0]:
        r, g, b = image_rgb[int(y), int(x)]
        return f"#{r:02x}{g:02x}{b:02x}"
    return "#000000"

# --- ì²´í¬ë¬´ëŠ¬ ë°°ê²½ ìƒì„± ---
def create_checker_background(width, height, checker_size=10):
    checker = Image.new('RGB', (width, height))
    for i in range(0, width, checker_size):
        for j in range(0, height, checker_size):
            color = (200, 200, 200) if (i // checker_size + j // checker_size) % 2 == 0 else (255, 255, 255)
            for x in range(i, min(i + checker_size, width)):
                for y in range(j, min(j + checker_size, height)):
                    checker.putpixel((x, y), color)
    return checker

# ===== UI ì„¤ì • =====
st.set_page_config(page_title="Sprite Maker + AI", layout="wide")
st.header("ğŸ¦– ìŠ¤í”„ë¼ì´íŠ¸ ìƒì„±ê¸°")

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
if 'current_step' not in st.session_state:
    st.session_state.current_step = 1
if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
if 'generated_video_path' not in st.session_state:
    st.session_state.generated_video_path = None
if 'video_frames' not in st.session_state:
    st.session_state.video_frames = None
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []
if 'logo_regions' not in st.session_state:
    st.session_state.logo_regions = []
if 'picked_color' not in st.session_state:
    st.session_state.picked_color = "#000000"
if 'loop_animation' not in st.session_state:
    st.session_state.loop_animation = False

# ===== ì‚¬ì´ë“œë°”: ëª¨ë“œ ì„ íƒ =====
with st.sidebar:
    st.subheader("ğŸ“Œ ì‘ì—… ëª¨ë“œ")
    app_mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ¤– AI ìƒì„± (ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤)", "ğŸ“¹ ë¹„ë””ì˜¤ ìˆ˜ì •"],
        key="app_mode"
    )

# ===== AI ìƒì„± ëª¨ë“œ =====
if "AI ìƒì„±" in app_mode:

    # ========== STEP 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ ==========
    st.subheader("ğŸ“¤ Step 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ")

    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ (PNG/JPG)",
        type=["png", "jpg", "jpeg"],
        key="ai_image_uploader"
    )

    if uploaded_image:
        st.session_state.uploaded_image = uploaded_image
        image = Image.open(uploaded_image)

        col1, col2 = st.columns([1, 2])
        with col1:
            st.image(image, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ({image.width}x{image.height})", width="stretch")

        with col2:
            st.success("âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ!")
            st.caption("ë‹¤ìŒ ë‹¨ê³„ì—ì„œ AIê°€ ì´ ì´ë¯¸ì§€ë¥¼ ì›€ì§ì´ëŠ” ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

        if st.session_state.current_step < 2:
            st.session_state.current_step = 2

    # ========== STEP 2: AI ë¹„ë””ì˜¤ ìƒì„± ==========
    if st.session_state.current_step >= 2 and st.session_state.uploaded_image:
        st.markdown("---")
        st.subheader("ğŸ¤– Step 2: AI ë¹„ë””ì˜¤ ìƒì„±")

        if not REPLICATE_API_TOKEN:
            st.warning("âš ï¸ Replicate API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            with st.expander("ğŸ”‘ API í† í° ì„¤ì • ë°©ë²•", expanded=True):
                st.markdown("""
**Streamlit Cloud ë°°í¬:**
1. ì•± ìš°ì¸¡ ìƒë‹¨ ë©”ë‰´ â†’ Settings â†’ Secrets
2. ì•„ë˜ ë‚´ìš©ì„ ì…ë ¥ í›„ Save:
```toml
REPLICATE_API_TOKEN = "your_token_here"
```
3. ì•±ì„ **Reboot** í•´ì£¼ì„¸ìš”

**ë¡œì»¬ ì‹¤í–‰:**
- í”„ë¡œì íŠ¸ í´ë”ì— `.env` íŒŒì¼ ìƒì„±
- `REPLICATE_API_TOKEN=your_token` ì¶”ê°€

ğŸ”— [Replicate API í† í° ë°œê¸‰](https://replicate.com/account/api-tokens)
                """)
            st.info("ğŸ’¡ API í† í° ì—†ì´ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¹„ë””ì˜¤ ìˆ˜ì •' ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        # AI ìƒì„± ì˜µì…˜
        with st.expander("ğŸ¬ AI ìƒì„± ì˜µì…˜", expanded=True):
            ai_prompt = st.text_area(
                "í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)",
                placeholder="ì˜ˆ: gentle swaying motion, breathing animation, subtle movement...",
                help="ì›í•˜ëŠ” ì›€ì§ì„ì„ ì„¤ëª…í•˜ì„¸ìš”. (í˜„ì¬ SVD ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ ì˜í–¥ì´ ì œí•œì )"
            )

            col1, col2, col3 = st.columns(3)
            with col1:
                video_length = st.selectbox(
                    "ë¹„ë””ì˜¤ ê¸¸ì´",
                    ["14_frames_with_svd", "25_frames_with_svd_xt"],
                    index=1
                )
            with col2:
                motion_bucket_id = st.slider("ëª¨ì…˜ ê°•ë„", 1, 255, 100, help="ë†’ì„ìˆ˜ë¡ ì›€ì§ì„ í¼")
            with col3:
                ai_fps = st.slider("FPS", 1, 30, 6)

            st.caption("âš ï¸ ëª¨ì…˜ ê°•ë„ê°€ ë†’ìœ¼ë©´ ì‹œì‘/ë í”„ë ˆì„ì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. AI ëª¨ë¸ íŠ¹ì„±ìƒ ì²˜ìŒê³¼ ë§ˆì§€ë§‰ ëª‡ í”„ë ˆì„ì€ ì™œê³¡ë  ìˆ˜ ìˆìœ¼ë‹ˆ, ì¶œë ¥ ì„¤ì •ì—ì„œ í”„ë ˆì„ íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

        # ì´ë¯¸ ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if st.session_state.generated_video_path and os.path.exists(st.session_state.generated_video_path):
            st.success("âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
            st.video(st.session_state.generated_video_path)

            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±í•˜ê¸°", width="stretch"):
                    st.session_state.generated_video_path = None
                    st.session_state.current_step = 2
                    st.rerun()
            with col2:
                if st.button("â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", width="stretch"):
                    st.session_state.current_step = 3
                    st.rerun()
        else:
            # AI ìƒì„± ë²„íŠ¼
            if st.button("ğŸš€ AI ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘", type="primary", width="stretch"):
                with st.status("ğŸ¤– AI ë¹„ë””ì˜¤ ìƒì„± ì¤‘...", expanded=True) as status:
                    st.write("â³ Stable Video Diffusion ì‹¤í–‰ ì¤‘...")
                    st.write("   ì•½ 2~5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.")

                    try:
                        st.session_state.uploaded_image.seek(0)
                        video_url = generate_video_from_image(
                            st.session_state.uploaded_image,
                            REPLICATE_API_TOKEN,
                            prompt=ai_prompt,
                            video_length=video_length,
                            motion_bucket_id=motion_bucket_id,
                            fps=ai_fps
                        )

                        st.write("âœ… ìƒì„± ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ì¤‘...")

                        response = requests.get(video_url)
                        video_temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                        video_temp.write(response.content)
                        video_temp.close()

                        st.session_state.generated_video_path = video_temp.name
                        status.update(label="âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete")
                        st.rerun()

                    except Exception as e:
                        status.update(label="âŒ ìƒì„± ì‹¤íŒ¨", state="error")
                        st.error(f"ì˜¤ë¥˜: {str(e)}")

    # ========== STEP 3: ë°°ê²½ ì œê±° ì„¤ì • ==========
    if st.session_state.current_step >= 3 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 3: ë°°ê²½ ì œê±° ì„¤ì •")

        # ë¹„ë””ì˜¤ì—ì„œ ì²« í”„ë ˆì„ ì¶”ì¶œ
        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„")

            # ë°°ê²½ ì œê±° ì˜µì…˜
            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                st.markdown("#### ğŸ¯ ë°°ê²½ìƒ‰ ì„ íƒ")
                st.caption("ìŠ¤í¬ì´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì§ì ‘ ë°°ê²½ìƒ‰ì„ ì„ íƒí•˜ê±°ë‚˜, ì•„ë˜ ìƒ‰ìƒ í”¼ì»¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

                # ìŠ¤í¬ì´ë“œ ë„êµ¬ UI
                eyedropper_col1, eyedropper_col2 = st.columns([2, 1])

                with eyedropper_col1:
                    # ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚° (ìº”ë²„ìŠ¤ìš©)
                    max_canvas_width = 400
                    scale = max_canvas_width / video_width if video_width > max_canvas_width else 1.0
                    canvas_width = int(video_width * scale)
                    canvas_height = int(video_height * scale)

                    # ìº”ë²„ìŠ¤ì— í‘œì‹œí•  ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                    frame_pil = Image.fromarray(first_frame_rgb)
                    if scale < 1.0:
                        frame_pil = frame_pil.resize((canvas_width, canvas_height), Image.Resampling.LANCZOS)

                    st.markdown("**ğŸ” ìŠ¤í¬ì´ë“œ: ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ìƒ‰ìƒ ì„ íƒ**")
                    canvas_result = st_canvas(
                        fill_color="rgba(255, 0, 0, 0.3)",
                        stroke_width=1,
                        stroke_color="#FF0000",
                        background_image=frame_pil,
                        height=canvas_height,
                        width=canvas_width,
                        drawing_mode="point",
                        point_display_radius=3,
                        key="eyedropper_canvas_ai",
                    )

                    # ìŠ¤í¬ì´ë“œë¡œ ìƒ‰ìƒ ì„ íƒ ì²˜ë¦¬
                    if canvas_result.json_data is not None:
                        objects = canvas_result.json_data.get("objects", [])
                        if objects:
                            # ê°€ì¥ ìµœê·¼ í´ë¦­ ìœ„ì¹˜ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ
                            latest_obj = objects[-1]
                            if latest_obj.get("type") == "circle":
                                cx = int(latest_obj.get("left", 0) / scale)
                                cy = int(latest_obj.get("top", 0) / scale)
                                picked = get_color_at_position(first_frame_rgb, cx, cy)
                                if picked != st.session_state.picked_color:
                                    st.session_state.picked_color = picked
                                    st.rerun()

                with eyedropper_col2:
                    st.markdown("**ì„ íƒëœ ìƒ‰ìƒ**")
                    st.markdown(f"""
                    <div style="
                        width: 80px;
                        height: 80px;
                        background-color: {st.session_state.picked_color};
                        border: 2px solid #333;
                        border-radius: 8px;
                        margin: 10px 0;
                    "></div>
                    """, unsafe_allow_html=True)
                    st.code(st.session_state.picked_color)

                    if st.button("ğŸ”„ ìŠ¤í¬ì´ë“œ ì´ˆê¸°í™”", key="reset_eyedropper_ai"):
                        st.session_state.picked_color = "#000000"
                        st.rerun()

                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", st.session_state.picked_color, key="bg_color_ai")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100)
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3)

            # ì¶œë ¥ ì„¤ì •
            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                # í”„ë ˆì„ íŠ¸ë¦¬ë° ì˜µì…˜ (AI ìƒì„± ëª¨ë“œì—ì„œ ê¸°ë³¸ í™œì„±í™”)
                st.markdown("#### âœ‚ï¸ í”„ë ˆì„ íŠ¸ë¦¬ë°")
                st.caption("AI ìƒì„± ë¹„ë””ì˜¤ì˜ ì‹œì‘/ë ë¶ˆì•ˆì •í•œ í”„ë ˆì„ì„ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.")
                trim_col1, trim_col2 = st.columns(2)
                with trim_col1:
                    skip_start_frames = st.number_input("ì‹œì‘ í”„ë ˆì„ ì œê±°", 0, 10, 2, key="skip_start_ai",
                                                        help="ë¹„ë””ì˜¤ ì‹œì‘ ë¶€ë¶„ì—ì„œ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜")
                with trim_col2:
                    skip_end_frames = st.number_input("ë í”„ë ˆì„ ì œê±°", 0, 10, 2, key="skip_end_ai",
                                                      help="ë¹„ë””ì˜¤ ë ë¶€ë¶„ì—ì„œ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜")

                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width)
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height)
                    else:
                        output_width, output_height = video_width, video_height

                with col2:
                    frame_interval = st.number_input("í”„ë ˆì„ ì¶”ì¶œ ê°„ê²©", 1, 30, 1)
                    # íŠ¸ë¦¬ë° í›„ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
                    available_frames = max(1, total_frames - skip_start_frames - skip_end_frames)
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, available_frames, min(available_frames, 100))

                gif_speed = st.slider("GIF ì†ë„ (ms/í”„ë ˆì„)", 10, 500, 100)

                # ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ ì˜µì…˜
                st.markdown("---")
                st.markdown("#### ğŸ”„ ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜")
                loop_animation = st.checkbox("ë£¨í”„ ëª¨ë“œ (ìˆœë°©í–¥+ì—­ë°©í–¥)", value=False, key="loop_ai",
                                            help="GIF ìƒì„± ì‹œ í”„ë ˆì„ì„ ìˆœë°©í–¥+ì—­ë°©í–¥ìœ¼ë¡œ ì´ì–´ë¶™ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë£¨í”„ ìƒì„± (ì˜ˆ: 1,2,3,4,5 â†’ 1,2,3,4,5,4,3,2)")
                st.session_state.loop_animation = loop_animation

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")
                st.caption("ğŸ”² ì²´í¬ë¬´ëŠ¬ = íˆ¬ëª… ì˜ì—­")

            # ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜ ë²„íŠ¼
            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, st.session_state.logo_regions,
                        skip_start_frames, skip_end_frames
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 4
                    st.rerun()

# ===== ë¹„ë””ì˜¤ ìˆ˜ì • ëª¨ë“œ =====
else:
    # ========== STEP 1: ë¹„ë””ì˜¤ ìˆ˜ì • ==========
    st.subheader("ğŸ“¤ Step 1: ë¹„ë””ì˜¤ ìˆ˜ì •")

    uploaded_video = st.file_uploader(
        "ë¹„ë””ì˜¤ íŒŒì¼ (MP4/MOV/AVI)",
        type=["mp4", "mov", "avi"],
        key="video_uploader"
    )

    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.close()
        st.session_state.generated_video_path = tfile.name

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„ | {video_fps:.1f}fps")

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
            st.image(first_frame_rgb, caption="ì²« í”„ë ˆì„", width="stretch")

        st.session_state.current_step = 2

    # ========== STEP 2: ë°°ê²½ ì„¤ì • ==========
    if st.session_state.current_step >= 2 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 2: ë°°ê²½ ì œê±° ì„¤ì •")

        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                st.markdown("#### ğŸ¯ ë°°ê²½ìƒ‰ ì„ íƒ")
                st.caption("ìŠ¤í¬ì´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì§ì ‘ ë°°ê²½ìƒ‰ì„ ì„ íƒí•˜ê±°ë‚˜, ì•„ë˜ ìƒ‰ìƒ í”¼ì»¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

                # ìŠ¤í¬ì´ë“œ ë„êµ¬ UI
                eyedropper_col1, eyedropper_col2 = st.columns([2, 1])

                with eyedropper_col1:
                    # ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚° (ìº”ë²„ìŠ¤ìš©)
                    max_canvas_width = 400
                    scale_video = max_canvas_width / video_width if video_width > max_canvas_width else 1.0
                    canvas_width_v = int(video_width * scale_video)
                    canvas_height_v = int(video_height * scale_video)

                    # ìº”ë²„ìŠ¤ì— í‘œì‹œí•  ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                    frame_pil_v = Image.fromarray(first_frame_rgb)
                    if scale_video < 1.0:
                        frame_pil_v = frame_pil_v.resize((canvas_width_v, canvas_height_v), Image.Resampling.LANCZOS)

                    st.markdown("**ğŸ” ìŠ¤í¬ì´ë“œ: ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ìƒ‰ìƒ ì„ íƒ**")
                    canvas_result_v = st_canvas(
                        fill_color="rgba(255, 0, 0, 0.3)",
                        stroke_width=1,
                        stroke_color="#FF0000",
                        background_image=frame_pil_v,
                        height=canvas_height_v,
                        width=canvas_width_v,
                        drawing_mode="point",
                        point_display_radius=3,
                        key="eyedropper_canvas_video",
                    )

                    # ìŠ¤í¬ì´ë“œë¡œ ìƒ‰ìƒ ì„ íƒ ì²˜ë¦¬
                    if canvas_result_v.json_data is not None:
                        objects_v = canvas_result_v.json_data.get("objects", [])
                        if objects_v:
                            latest_obj_v = objects_v[-1]
                            if latest_obj_v.get("type") == "circle":
                                cx_v = int(latest_obj_v.get("left", 0) / scale_video)
                                cy_v = int(latest_obj_v.get("top", 0) / scale_video)
                                picked_v = get_color_at_position(first_frame_rgb, cx_v, cy_v)
                                if picked_v != st.session_state.picked_color:
                                    st.session_state.picked_color = picked_v
                                    st.rerun()

                with eyedropper_col2:
                    st.markdown("**ì„ íƒëœ ìƒ‰ìƒ**")
                    st.markdown(f"""
                    <div style="
                        width: 80px;
                        height: 80px;
                        background-color: {st.session_state.picked_color};
                        border: 2px solid #333;
                        border-radius: 8px;
                        margin: 10px 0;
                    "></div>
                    """, unsafe_allow_html=True)
                    st.code(st.session_state.picked_color)

                    if st.button("ğŸ”„ ìŠ¤í¬ì´ë“œ ì´ˆê¸°í™”", key="reset_eyedropper_video"):
                        st.session_state.picked_color = "#000000"
                        st.rerun()

                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", st.session_state.picked_color, key="video_bg")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100, key="video_tol")
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3, key="video_edge")

            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                # í”„ë ˆì„ íŠ¸ë¦¬ë° ì˜µì…˜ (ë¹„ë””ì˜¤ ìˆ˜ì • ëª¨ë“œì—ì„œëŠ” ê¸°ë³¸ ë¹„í™œì„±í™”)
                st.markdown("#### âœ‚ï¸ í”„ë ˆì„ íŠ¸ë¦¬ë°")
                st.caption("ë¹„ë””ì˜¤ì˜ ì‹œì‘/ë í”„ë ˆì„ì„ ì œê±°í•©ë‹ˆë‹¤.")
                trim_col1_v, trim_col2_v = st.columns(2)
                with trim_col1_v:
                    skip_start_frames_v = st.number_input("ì‹œì‘ í”„ë ˆì„ ì œê±°", 0, 10, 0, key="skip_start_video",
                                                          help="ë¹„ë””ì˜¤ ì‹œì‘ ë¶€ë¶„ì—ì„œ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜")
                with trim_col2_v:
                    skip_end_frames_v = st.number_input("ë í”„ë ˆì„ ì œê±°", 0, 10, 0, key="skip_end_video",
                                                        help="ë¹„ë””ì˜¤ ë ë¶€ë¶„ì—ì„œ ê±´ë„ˆë›¸ í”„ë ˆì„ ìˆ˜")

                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •", key="video_custom")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width, key="video_w")
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height, key="video_h")
                    else:
                        output_width, output_height = video_width, video_height
                with col2:
                    frame_interval = st.number_input("ì¶”ì¶œ ê°„ê²©", 1, 30, 1, key="video_int")
                    available_frames_v = max(1, total_frames - skip_start_frames_v - skip_end_frames_v)
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, available_frames_v, min(available_frames_v, 100), key="video_max")

                gif_speed = st.slider("GIF ì†ë„", 10, 500, 100, key="video_gif")

                # ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ ì˜µì…˜
                st.markdown("---")
                st.markdown("#### ğŸ”„ ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜")
                loop_animation_v = st.checkbox("ë£¨í”„ ëª¨ë“œ (ìˆœë°©í–¥+ì—­ë°©í–¥)", value=False, key="loop_video",
                                              help="GIF ìƒì„± ì‹œ í”„ë ˆì„ì„ ìˆœë°©í–¥+ì—­ë°©í–¥ìœ¼ë¡œ ì´ì–´ë¶™ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë£¨í”„ ìƒì„±")
                st.session_state.loop_animation = loop_animation_v

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")

            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch", key="video_convert"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, [],
                        skip_start_frames_v, skip_end_frames_v
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 3
                    st.rerun()

# ===== ê²°ê³¼ë¬¼ í‘œì‹œ =====
if st.session_state.processed_images:
    st.markdown("---")
    st.header("ğŸ“¦ ê²°ê³¼ë¬¼")

    processed_pil_images = st.session_state.processed_images
    current_gif_speed = st.session_state.get('gif_speed', 100)

    tab1, tab2, tab3 = st.tabs(["ğŸ¬ GIF", "ğŸ“„ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸", "ğŸ–¼ï¸ í”„ë ˆì„ ì„ íƒ"])

    with tab1:
        # ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ ì²˜ë¦¬
        gif_frames = processed_pil_images.copy()
        if st.session_state.get('loop_animation', False) and len(gif_frames) > 2:
            # ìˆœë°©í–¥ + ì—­ë°©í–¥ (ì²« í”„ë ˆì„ê³¼ ë§ˆì§€ë§‰ í”„ë ˆì„ ì œì™¸í•˜ê³  ì—­ìˆœ)
            # ì˜ˆ: [1,2,3,4,5] â†’ [1,2,3,4,5,4,3,2]
            reversed_frames = gif_frames[-2:0:-1]  # ë§ˆì§€ë§‰ í”„ë ˆì„ ì œì™¸, ì—­ìˆœ, ì²« í”„ë ˆì„ ì œì™¸
            gif_frames = gif_frames + reversed_frames
            st.info(f"ğŸ”„ ë£¨í”„ ëª¨ë“œ: {len(processed_pil_images)}í”„ë ˆì„ â†’ {len(gif_frames)}í”„ë ˆì„ (ìˆœë°©í–¥+ì—­ë°©í–¥)")

        # RGBA ì´ë¯¸ì§€ë¥¼ íˆ¬ëª… ë°°ê²½ GIFë¡œ ì˜¬ë°”ë¥´ê²Œ ë³€í™˜
        gif_buffer = io.BytesIO()
        # ì²« í”„ë ˆì„ì„ P ëª¨ë“œ(íŒ”ë ˆíŠ¸)ë¡œ ë³€í™˜í•˜ê³  íˆ¬ëª… ìƒ‰ìƒ ì¸ë±ìŠ¤ ì„¤ì •
        converted_frames = []
        for frame in gif_frames:
            # RGBAì—ì„œ íˆ¬ëª… ì˜ì—­ì„ íŠ¹ì • ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
            if frame.mode == 'RGBA':
                # íˆ¬ëª… ì˜ì—­ì„ ë§ˆì  íƒ€(255, 0, 255)ë¡œ ì±„ì›€ (íˆ¬ëª… ë§ˆì»¤)
                background = Image.new('RGBA', frame.size, (255, 0, 255, 255))
                # ì•ŒíŒŒ ì±„ë„ì„ ì‚¬ìš©í•˜ì—¬ í•©ì„±
                composite = Image.alpha_composite(background, frame)
                # P ëª¨ë“œë¡œ ë³€í™˜í•˜ê³  ë§ˆì  íƒ€ë¥¼ íˆ¬ëª…ìœ¼ë¡œ ì„¤ì •
                p_frame = composite.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=255)
                # íˆ¬ëª… ìƒ‰ìƒ ì¸ë±ìŠ¤ ì°¾ê¸°
                palette = p_frame.getpalette()
                trans_index = 0
                for i in range(256):
                    if palette[i*3:i*3+3] == [255, 0, 255]:
                        trans_index = i
                        break
                converted_frames.append((p_frame, trans_index))
            else:
                converted_frames.append((frame.convert('P', palette=Image.ADAPTIVE, colors=256), None))

        if converted_frames:
            first_frame, first_trans = converted_frames[0]
            append_frames = [f[0] for f in converted_frames[1:]]

            first_frame.save(
                gif_buffer, format="GIF", save_all=True,
                append_images=append_frames,
                duration=current_gif_speed, loop=0, disposal=2,
                transparency=first_trans if first_trans is not None else 0
            )

        st.image(gif_buffer.getvalue(), caption="íˆ¬ëª… ë°°ê²½ GIF")

        # APNGë„ ìƒì„± (ì™„ë²½í•œ íˆ¬ëª…ë„ ì§€ì›)
        apng_buffer = io.BytesIO()
        gif_frames[0].save(
            apng_buffer, format="PNG", save_all=True,
            append_images=gif_frames[1:],
            duration=current_gif_speed, loop=0
        )

        dl_col1, dl_col2 = st.columns(2)
        with dl_col1:
            st.download_button("ğŸ¬ GIF ë‹¤ìš´ë¡œë“œ", gif_buffer.getvalue(), "animation.gif", "image/gif", width="stretch")
        with dl_col2:
            st.download_button("ğŸ–¼ï¸ APNG ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)", apng_buffer.getvalue(), "animation.png", "image/png", width="stretch",
                              help="APNGëŠ” ì™„ë²½í•œ íˆ¬ëª…ë„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. GIFë³´ë‹¤ í™”ì§ˆì´ ì¢‹ìŠµë‹ˆë‹¤.")

    with tab2:
        sheet_cols = st.number_input("ì—´ ìˆ˜ (0=ê°€ë¡œ í•œ ì¤„)", 0, len(processed_pil_images), 0)
        sprite_sheet = create_sprite_sheet(processed_pil_images, sheet_cols)
        sheet_buffer = io.BytesIO()
        sprite_sheet.save(sheet_buffer, format="PNG")
        st.image(sprite_sheet, caption=f"ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ({sprite_sheet.width}x{sprite_sheet.height})")

        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“„ PNG ì €ì¥", sheet_buffer.getvalue(), "sprite_sheet.png", "image/png", width="stretch")
        with col2:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for idx, img in enumerate(processed_pil_images):
                    img_arr = io.BytesIO()
                    img.save(img_arr, format="PNG")
                    zf.writestr(f"frame_{idx:03d}.png", img_arr.getvalue())
            st.download_button("ğŸ“¦ ZIP ì €ì¥", zip_buffer.getvalue(), "frames.zip", "application/zip", width="stretch")

    with tab3:
        if 'selected_frames' not in st.session_state:
            st.session_state.selected_frames = list(range(len(processed_pil_images)))

        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì „ì²´ ì„ íƒ", width="stretch"):
                st.session_state.selected_frames = list(range(len(processed_pil_images)))
                st.rerun()
        with col2:
            if st.button("âŒ ì „ì²´ í•´ì œ", width="stretch"):
                st.session_state.selected_frames = []
                st.rerun()

        cols_per_row = 6
        for row_start in range(0, len(processed_pil_images), cols_per_row):
            cols = st.columns(cols_per_row)
            for col_idx, img_idx in enumerate(range(row_start, min(row_start + cols_per_row, len(processed_pil_images)))):
                with cols[col_idx]:
                    is_sel = img_idx in st.session_state.selected_frames
                    if st.checkbox(f"#{img_idx+1}", value=is_sel, key=f"sel_{img_idx}"):
                        if img_idx not in st.session_state.selected_frames:
                            st.session_state.selected_frames.append(img_idx)
                    else:
                        if img_idx in st.session_state.selected_frames:
                            st.session_state.selected_frames.remove(img_idx)
                    thumb = processed_pil_images[img_idx].copy()
                    thumb.thumbnail((80, 80))
                    st.image(thumb)

        if st.session_state.selected_frames:
            st.info(f"ì„ íƒ: {len(st.session_state.selected_frames)}ê°œ")
            selected_imgs = [processed_pil_images[i] for i in sorted(st.session_state.selected_frames)]
            custom_cols = st.number_input("ì—´ ìˆ˜", 0, len(selected_imgs), 0, key="custom_cols")
            custom_sheet = create_sprite_sheet(selected_imgs, custom_cols)
            custom_buf = io.BytesIO()
            custom_sheet.save(custom_buf, format="PNG")
            st.image(custom_sheet)
            st.download_button("ğŸ“„ ì„ íƒ í”„ë ˆì„ ì €ì¥", custom_buf.getvalue(), "custom_sheet.png", "image/png", width="stretch")

    # ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°
    st.markdown("---")
    if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°", width="stretch"):
        st.session_state.current_step = 1
        st.session_state.uploaded_image = None
        st.session_state.generated_video_path = None
        st.session_state.processed_images = []
        st.session_state.selected_frames = []
        st.rerun()
