import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import zipfile
from PIL import Image, ImageDraw
import io
import requests
import base64
from dotenv import load_dotenv

# ============================================
# API í† í° ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
# ============================================

# 1. ë¡œì»¬ .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# 2. Streamlit Cloud secretsì—ì„œ í† í° ê°€ì ¸ì™€ì„œ os.environì— ê°•ì œ ì£¼ì…
try:
    if "REPLICATE_API_TOKEN" in st.secrets:
        os.environ["REPLICATE_API_TOKEN"] = st.secrets["REPLICATE_API_TOKEN"]
except FileNotFoundError:
    # secrets.toml íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° (ë¡œì»¬ í™˜ê²½)
    pass

# 3. ìµœì¢… í† í° ê°’ í™•ì¸
REPLICATE_API_TOKEN = os.environ.get("REPLICATE_API_TOKEN", "")

# Replicate import
try:
    import replicate
    REPLICATE_AVAILABLE = True
except ImportError:
    REPLICATE_AVAILABLE = False

# --- ë°°ê²½ ì œê±° í•¨ìˆ˜ ---
def remove_background(image, target_color, tolerance, edge_smoothing=0):
    """ë°°ê²½ìƒ‰ì„ ì œê±°í•˜ê³  íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)

    lower_bound = np.array([max(c - tolerance, 0) for c in target_color])
    upper_bound = np.array([min(c + tolerance, 255) for c in target_color])
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
    mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
    mask_inv = cv2.bitwise_not(mask)

    if edge_smoothing > 0:
        blur_size = edge_smoothing * 2 + 1
        mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
        kernel = np.ones((3, 3), np.uint8)
        mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)

    image[:, :, 3] = mask_inv
    return image

# --- ë¡œê³  ì˜ì—­ ì œê±° ---
def remove_logo_area(image, regions):
    """ì§€ì •ëœ ì˜ì—­ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¦"""
    if len(image.shape) == 3 and image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)
    for region in regions:
        x, y, w, h = int(region['x']), int(region['y']), int(region['width']), int(region['height'])
        x, y = max(0, x), max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)
        if w > 0 and h > 0:
            image[y:y+h, x:x+w, 3] = 0
    return image

# --- ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ---
def resize_image(pil_img, target_width, target_height):
    if target_width > 0 and target_height > 0:
        return pil_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    return pil_img

# --- ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„± ---
def create_sprite_sheet(images, columns=0):
    if not images:
        return None
    width, height = images[0].size
    total_images = len(images)

    if columns <= 0:
        total_width = width * total_images
        sheet = Image.new("RGBA", (total_width, height))
        for idx, img in enumerate(images):
            sheet.paste(img, (idx * width, 0))
    else:
        rows = (total_images + columns - 1) // columns
        sheet = Image.new("RGBA", (width * columns, height * rows))
        for idx, img in enumerate(images):
            sheet.paste(img, ((idx % columns) * width, (idx // columns) * height))
    return sheet

# --- ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (ë¯¸ë¦¬ë³´ê¸°ìš©) ---
def process_single_frame(frame_rgb, bg_color_rgb, tolerance, edge_smoothing, logo_regions=None):
    frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)

    if logo_regions:
        frame_bgra = remove_logo_area(frame_bgr.copy(), logo_regions)
        rgb_image = cv2.cvtColor(frame_bgra, cv2.COLOR_BGRA2RGB)
        lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
        upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
        mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
        mask_inv = cv2.bitwise_not(mask)
        if edge_smoothing > 0:
            blur_size = edge_smoothing * 2 + 1
            mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
            kernel = np.ones((3, 3), np.uint8)
            mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
        frame_bgra[:, :, 3] = cv2.bitwise_and(frame_bgra[:, :, 3], mask_inv)
        processed_cv = frame_bgra
    else:
        processed_cv = remove_background(frame_bgr, bg_color_rgb, tolerance, edge_smoothing)

    return Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

# --- AI ë¹„ë””ì˜¤ ìƒì„± ---
def generate_video_from_image(image_file, api_token, prompt="", video_length="25_frames_with_svd_xt", motion_bucket_id=127, fps=6):
    """Replicate APIë¡œ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ ìƒì„±"""
    os.environ["REPLICATE_API_TOKEN"] = api_token

    image_bytes = image_file.getvalue()
    base64_image = base64.b64encode(image_bytes).decode('utf-8')

    image_file.seek(0)
    header = image_file.read(8)
    image_file.seek(0)

    mime_type = "image/png" if header[:8] == b'\x89PNG\r\n\x1a\n' else "image/jpeg"
    data_uri = f"data:{mime_type};base64,{base64_image}"

    # Stable Video Diffusion ì‚¬ìš©
    output = replicate.run(
        "stability-ai/stable-video-diffusion:3f0457e4619daac51203dedb472816fd4af51f3149fa7a9e0b5ffcf1b8172438",
        input={
            "input_image": data_uri,
            "video_length": video_length,
            "motion_bucket_id": motion_bucket_id,
            "fps": fps
        }
    )

    return output

# --- ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ---
def process_video_to_sprites(video_path, bg_color_rgb, tolerance, edge_smoothing,
                              frame_interval, max_frames, use_custom_size,
                              output_width, output_height, logo_regions=None):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    processed_pil_images = []

    frame_idx = 0
    extracted_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_interval == 0 and extracted_count < max_frames:
            if logo_regions:
                frame = remove_logo_area(frame, logo_regions)
                processed_cv = frame.copy()
                rgb_image = cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGB)
                lower_bound = np.array([max(c - tolerance, 0) for c in bg_color_rgb])
                upper_bound = np.array([min(c + tolerance, 255) for c in bg_color_rgb])
                mask = cv2.inRange(rgb_image, lower_bound, upper_bound)
                mask_inv = cv2.bitwise_not(mask)
                if edge_smoothing > 0:
                    blur_size = edge_smoothing * 2 + 1
                    mask_inv = cv2.GaussianBlur(mask_inv, (blur_size, blur_size), 0)
                    kernel = np.ones((3, 3), np.uint8)
                    mask_inv = cv2.morphologyEx(mask_inv, cv2.MORPH_CLOSE, kernel)
                processed_cv[:, :, 3] = cv2.bitwise_and(processed_cv[:, :, 3], mask_inv)
            else:
                processed_cv = remove_background(frame, bg_color_rgb, tolerance, edge_smoothing)

            pil_img = Image.fromarray(cv2.cvtColor(processed_cv, cv2.COLOR_BGRA2RGBA))

            if use_custom_size and output_width > 0 and output_height > 0:
                pil_img = resize_image(pil_img, output_width, output_height)

            processed_pil_images.append(pil_img)
            extracted_count += 1

        frame_idx += 1
        if extracted_count >= max_frames:
            break

    cap.release()
    return processed_pil_images, total_frames

# --- ì²´í¬ë¬´ëŠ¬ ë°°ê²½ ìƒì„± ---
def create_checker_background(width, height, checker_size=10):
    checker = Image.new('RGB', (width, height))
    for i in range(0, width, checker_size):
        for j in range(0, height, checker_size):
            color = (200, 200, 200) if (i // checker_size + j // checker_size) % 2 == 0 else (255, 255, 255)
            for x in range(i, min(i + checker_size, width)):
                for y in range(j, min(j + checker_size, height)):
                    checker.putpixel((x, y), color)
    return checker

# --- ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ (ìŠ¤í¬ì´ë“œ) ---
def get_color_at_position(image_rgb, x, y):
    """ì´ë¯¸ì§€ì˜ íŠ¹ì • ì¢Œí‘œì—ì„œ RGB ìƒ‰ìƒ ì¶”ì¶œ"""
    if 0 <= x < image_rgb.shape[1] and 0 <= y < image_rgb.shape[0]:
        r, g, b = image_rgb[int(y), int(x)]
        return f"#{r:02x}{g:02x}{b:02x}"
    return "#000000"

# --- ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ ---
def extract_dominant_colors(image_rgb, n_colors=5):
    """ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì—ì„œ ì£¼ìš” ë°°ê²½ìƒ‰ í›„ë³´ ì¶”ì¶œ"""
    h, w = image_rgb.shape[:2]
    # ê°€ì¥ìë¦¬ í”½ì…€ ìˆ˜ì§‘ (ìƒí•˜ì¢Œìš° 10í”½ì…€)
    edge_size = min(10, h // 4, w // 4)
    edges = []
    edges.extend(image_rgb[:edge_size, :].reshape(-1, 3).tolist())  # ìƒë‹¨
    edges.extend(image_rgb[-edge_size:, :].reshape(-1, 3).tolist())  # í•˜ë‹¨
    edges.extend(image_rgb[:, :edge_size].reshape(-1, 3).tolist())  # ì¢Œì¸¡
    edges.extend(image_rgb[:, -edge_size:].reshape(-1, 3).tolist())  # ìš°ì¸¡

    # ìƒ‰ìƒ ë¹ˆë„ ê³„ì‚°
    from collections import Counter
    color_counts = Counter([tuple(c) for c in edges])
    most_common = color_counts.most_common(n_colors)

    return [f"#{r:02x}{g:02x}{b:02x}" for (r, g, b), _ in most_common]

# ===== UI ì„¤ì • =====
st.set_page_config(page_title="Sprite Maker + AI", layout="wide")
st.header("ğŸ¦– ìŠ¤í”„ë¼ì´íŠ¸ ìƒì„±ê¸°")

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
if 'current_step' not in st.session_state:
    st.session_state.current_step = 1
if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
if 'generated_video_path' not in st.session_state:
    st.session_state.generated_video_path = None
if 'video_frames' not in st.session_state:
    st.session_state.video_frames = None
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []
if 'logo_regions' not in st.session_state:
    st.session_state.logo_regions = []
if 'picked_color' not in st.session_state:
    st.session_state.picked_color = "#000000"

# ===== ì‚¬ì´ë“œë°”: ëª¨ë“œ ì„ íƒ =====
with st.sidebar:
    st.subheader("ğŸ“Œ ì‘ì—… ëª¨ë“œ")
    app_mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ¤– AI ìƒì„± (ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤)", "ğŸ“¹ ë¹„ë””ì˜¤ ìˆ˜ì •"],
        key="app_mode"
    )

# ===== AI ìƒì„± ëª¨ë“œ =====
if "AI ìƒì„±" in app_mode:

    # ========== STEP 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ ==========
    st.subheader("ğŸ“¤ Step 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ")

    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ (PNG/JPG)",
        type=["png", "jpg", "jpeg"],
        key="ai_image_uploader"
    )

    if uploaded_image:
        st.session_state.uploaded_image = uploaded_image
        image = Image.open(uploaded_image)

        col1, col2 = st.columns([1, 2])
        with col1:
            st.image(image, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ({image.width}x{image.height})", width="stretch")

        with col2:
            st.success("âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ!")
            st.caption("ë‹¤ìŒ ë‹¨ê³„ì—ì„œ AIê°€ ì´ ì´ë¯¸ì§€ë¥¼ ì›€ì§ì´ëŠ” ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

        if st.session_state.current_step < 2:
            st.session_state.current_step = 2

    # ========== STEP 2: AI ë¹„ë””ì˜¤ ìƒì„± ==========
    if st.session_state.current_step >= 2 and st.session_state.uploaded_image:
        st.markdown("---")
        st.subheader("ğŸ¤– Step 2: AI ë¹„ë””ì˜¤ ìƒì„±")

        if not REPLICATE_API_TOKEN:
            st.warning("âš ï¸ Replicate API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            with st.expander("ğŸ”‘ API í† í° ì„¤ì • ë°©ë²•", expanded=True):
                st.markdown("""
**Streamlit Cloud ë°°í¬:**
1. ì•± ìš°ì¸¡ ìƒë‹¨ ë©”ë‰´ â†’ Settings â†’ Secrets
2. ì•„ë˜ ë‚´ìš©ì„ ì…ë ¥ í›„ Save:
```toml
REPLICATE_API_TOKEN = "your_token_here"
```
3. ì•±ì„ **Reboot** í•´ì£¼ì„¸ìš”

**ë¡œì»¬ ì‹¤í–‰:**
- í”„ë¡œì íŠ¸ í´ë”ì— `.env` íŒŒì¼ ìƒì„±
- `REPLICATE_API_TOKEN=your_token` ì¶”ê°€

ğŸ”— [Replicate API í† í° ë°œê¸‰](https://replicate.com/account/api-tokens)
                """)
            st.info("ğŸ’¡ API í† í° ì—†ì´ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¹„ë””ì˜¤ ìˆ˜ì •' ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        # AI ìƒì„± ì˜µì…˜
        with st.expander("ğŸ¬ AI ìƒì„± ì˜µì…˜", expanded=True):
            ai_prompt = st.text_area(
                "í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)",
                placeholder="ì˜ˆ: gentle swaying motion, breathing animation, subtle movement...",
                help="ì›í•˜ëŠ” ì›€ì§ì„ì„ ì„¤ëª…í•˜ì„¸ìš”. (í˜„ì¬ SVD ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ ì˜í–¥ì´ ì œí•œì )"
            )

            col1, col2, col3 = st.columns(3)
            with col1:
                video_length = st.selectbox(
                    "ë¹„ë””ì˜¤ ê¸¸ì´",
                    ["14_frames_with_svd", "25_frames_with_svd_xt"],
                    index=1
                )
            with col2:
                motion_bucket_id = st.slider("ëª¨ì…˜ ê°•ë„", 1, 255, 127, help="ë†’ì„ìˆ˜ë¡ ì›€ì§ì„ í¼")
            with col3:
                ai_fps = st.slider("FPS", 1, 30, 6)

        # ì´ë¯¸ ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if st.session_state.generated_video_path and os.path.exists(st.session_state.generated_video_path):
            st.success("âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
            st.video(st.session_state.generated_video_path)

            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±í•˜ê¸°", width="stretch"):
                    st.session_state.generated_video_path = None
                    st.session_state.current_step = 2
                    st.rerun()
            with col2:
                if st.button("â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", width="stretch"):
                    st.session_state.current_step = 3
                    st.rerun()
        else:
            # AI ìƒì„± ë²„íŠ¼
            if st.button("ğŸš€ AI ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘", type="primary", width="stretch"):
                with st.status("ğŸ¤– AI ë¹„ë””ì˜¤ ìƒì„± ì¤‘...", expanded=True) as status:
                    st.write("â³ Stable Video Diffusion ì‹¤í–‰ ì¤‘...")
                    st.write("   ì•½ 2~5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.")

                    try:
                        st.session_state.uploaded_image.seek(0)
                        video_url = generate_video_from_image(
                            st.session_state.uploaded_image,
                            REPLICATE_API_TOKEN,
                            prompt=ai_prompt,
                            video_length=video_length,
                            motion_bucket_id=motion_bucket_id,
                            fps=ai_fps
                        )

                        st.write("âœ… ìƒì„± ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ì¤‘...")

                        response = requests.get(video_url)
                        video_temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                        video_temp.write(response.content)
                        video_temp.close()

                        st.session_state.generated_video_path = video_temp.name
                        status.update(label="âœ… AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete")
                        st.rerun()

                    except Exception as e:
                        status.update(label="âŒ ìƒì„± ì‹¤íŒ¨", state="error")
                        st.error(f"ì˜¤ë¥˜: {str(e)}")

    # ========== STEP 3: ë°°ê²½ ì œê±° ì„¤ì • ==========
    if st.session_state.current_step >= 3 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 3: ë°°ê²½ ì œê±° ì„¤ì •")

        # ë¹„ë””ì˜¤ì—ì„œ ì²« í”„ë ˆì„ ì¶”ì¶œ
        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„")

            # ë°°ê²½ ì œê±° ì˜µì…˜
            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                st.markdown("#### ğŸ¯ ë°°ê²½ìƒ‰ ì„ íƒ")

                # ìë™ ì¶”ì¶œëœ ë°°ê²½ìƒ‰ í›„ë³´
                dominant_colors = extract_dominant_colors(first_frame_rgb, 5)
                st.caption("ğŸ“Œ ì¶”ì²œ ë°°ê²½ìƒ‰ (ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì—ì„œ ìë™ ê°ì§€)")
                color_cols = st.columns(len(dominant_colors))
                for i, color in enumerate(dominant_colors):
                    with color_cols[i]:
                        if st.button(f"â– ", key=f"color_btn_ai_{i}", help=color):
                            st.session_state.picked_color = color
                            st.rerun()
                        st.markdown(f"<div style='width:100%;height:20px;background:{color};border:1px solid #333;border-radius:3px;'></div>", unsafe_allow_html=True)

                st.markdown("---")

                # ìŠ¤í¬ì´ë“œ: ì¢Œí‘œë¡œ ìƒ‰ìƒ ì¶”ì¶œ
                st.caption("ğŸ” ìŠ¤í¬ì´ë“œ: ì¢Œí‘œë¥¼ ì…ë ¥í•˜ì—¬ ìƒ‰ìƒ ì¶”ì¶œ")
                sp_col1, sp_col2, sp_col3 = st.columns([1, 1, 1])
                with sp_col1:
                    pick_x = st.number_input("X ì¢Œí‘œ", 0, video_width - 1, 0, key="pick_x_ai")
                with sp_col2:
                    pick_y = st.number_input("Y ì¢Œí‘œ", 0, video_height - 1, 0, key="pick_y_ai")
                with sp_col3:
                    st.markdown("<br>", unsafe_allow_html=True)
                    if st.button("ğŸ¨ ìƒ‰ìƒ ì¶”ì¶œ", key="pick_color_ai"):
                        picked = get_color_at_position(first_frame_rgb, pick_x, pick_y)
                        st.session_state.picked_color = picked
                        st.rerun()

                st.markdown(f"**ì„ íƒëœ ìƒ‰ìƒ:** `{st.session_state.picked_color}`")
                st.markdown(f"<div style='width:60px;height:30px;background:{st.session_state.picked_color};border:2px solid #333;border-radius:5px;display:inline-block;'></div>", unsafe_allow_html=True)

                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", st.session_state.picked_color, key="bg_picker_ai")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100)
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3)

            # ì¶œë ¥ ì„¤ì •
            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width)
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height)
                    else:
                        output_width, output_height = video_width, video_height

                with col2:
                    frame_interval = st.number_input("í”„ë ˆì„ ì¶”ì¶œ ê°„ê²©", 1, 30, 1)
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, total_frames, min(total_frames, 100))

                gif_speed = st.slider("GIF ì†ë„ (ms/í”„ë ˆì„)", 10, 500, 100)

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")
                st.caption("ğŸ”² ì²´í¬ë¬´ëŠ¬ = íˆ¬ëª… ì˜ì—­")

            # ìŠ¤í”„ë¼ì´íŠ¸ ë³€í™˜ ë²„íŠ¼
            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, st.session_state.logo_regions
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 4
                    st.rerun()

# ===== ë¹„ë””ì˜¤ ìˆ˜ì • ëª¨ë“œ =====
else:
    # ========== STEP 1: ë¹„ë””ì˜¤ ìˆ˜ì • ==========
    st.subheader("ğŸ“¤ Step 1: ë¹„ë””ì˜¤ ìˆ˜ì •")

    uploaded_video = st.file_uploader(
        "ë¹„ë””ì˜¤ íŒŒì¼ (MP4/MOV/AVI)",
        type=["mp4", "mov", "avi"],
        key="video_uploader"
    )

    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.close()
        st.session_state.generated_video_path = tfile.name

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {video_width}x{video_height} | {total_frames}í”„ë ˆì„ | {video_fps:.1f}fps")

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
            st.image(first_frame_rgb, caption="ì²« í”„ë ˆì„", width="stretch")

        st.session_state.current_step = 2

    # ========== STEP 2: ë°°ê²½ ì„¤ì • ==========
    if st.session_state.current_step >= 2 and st.session_state.generated_video_path:
        st.markdown("---")
        st.subheader("âš™ï¸ Step 2: ë°°ê²½ ì œê±° ì„¤ì •")

        cap = cv2.VideoCapture(st.session_state.generated_video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        ret, first_frame = cap.read()
        cap.release()

        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)

            with st.expander("ğŸ¨ ë°°ê²½ ì œê±° ì˜µì…˜", expanded=True):
                st.markdown("#### ğŸ¯ ë°°ê²½ìƒ‰ ì„ íƒ")

                # ìë™ ì¶”ì¶œëœ ë°°ê²½ìƒ‰ í›„ë³´
                dominant_colors_v = extract_dominant_colors(first_frame_rgb, 5)
                st.caption("ğŸ“Œ ì¶”ì²œ ë°°ê²½ìƒ‰ (ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì—ì„œ ìë™ ê°ì§€)")
                color_cols_v = st.columns(len(dominant_colors_v))
                for i, color in enumerate(dominant_colors_v):
                    with color_cols_v[i]:
                        if st.button(f"â– ", key=f"color_btn_video_{i}", help=color):
                            st.session_state.picked_color = color
                            st.rerun()
                        st.markdown(f"<div style='width:100%;height:20px;background:{color};border:1px solid #333;border-radius:3px;'></div>", unsafe_allow_html=True)

                st.markdown("---")

                # ìŠ¤í¬ì´ë“œ: ì¢Œí‘œë¡œ ìƒ‰ìƒ ì¶”ì¶œ
                st.caption("ğŸ” ìŠ¤í¬ì´ë“œ: ì¢Œí‘œë¥¼ ì…ë ¥í•˜ì—¬ ìƒ‰ìƒ ì¶”ì¶œ")
                sp_col1_v, sp_col2_v, sp_col3_v = st.columns([1, 1, 1])
                with sp_col1_v:
                    pick_x_v = st.number_input("X ì¢Œí‘œ", 0, video_width - 1, 0, key="pick_x_video")
                with sp_col2_v:
                    pick_y_v = st.number_input("Y ì¢Œí‘œ", 0, video_height - 1, 0, key="pick_y_video")
                with sp_col3_v:
                    st.markdown("<br>", unsafe_allow_html=True)
                    if st.button("ğŸ¨ ìƒ‰ìƒ ì¶”ì¶œ", key="pick_color_video"):
                        picked_v = get_color_at_position(first_frame_rgb, pick_x_v, pick_y_v)
                        st.session_state.picked_color = picked_v
                        st.rerun()

                st.markdown(f"**ì„ íƒëœ ìƒ‰ìƒ:** `{st.session_state.picked_color}`")
                st.markdown(f"<div style='width:60px;height:30px;background:{st.session_state.picked_color};border:2px solid #333;border-radius:5px;display:inline-block;'></div>", unsafe_allow_html=True)

                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                with col1:
                    bg_color_hex = st.color_picker("ì œê±°í•  ë°°ê²½ìƒ‰", st.session_state.picked_color, key="video_bg")
                with col2:
                    tolerance = st.slider("ë¯¼ê°ë„", 0, 150, 100, key="video_tol")
                with col3:
                    edge_smoothing = st.slider("ê²½ê³„ì„  ë¶€ë“œëŸ½ê²Œ", 0, 10, 3, key="video_edge")

            with st.expander("ğŸ“ ì¶œë ¥ ì„¤ì •", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    use_custom_size = st.checkbox("í¬ê¸° ì§ì ‘ ì§€ì •", key="video_custom")
                    if use_custom_size:
                        output_width = st.number_input("ë„ˆë¹„", 1, 4096, video_width, key="video_w")
                        output_height = st.number_input("ë†’ì´", 1, 4096, video_height, key="video_h")
                    else:
                        output_width, output_height = video_width, video_height
                with col2:
                    frame_interval = st.number_input("ì¶”ì¶œ ê°„ê²©", 1, 30, 1, key="video_int")
                    max_frames = st.number_input("ìµœëŒ€ í”„ë ˆì„", 1, total_frames, min(total_frames, 100), key="video_max")

                gif_speed = st.slider("GIF ì†ë„", 10, 500, 100, key="video_gif")

            # ë¯¸ë¦¬ë³´ê¸°
            st.markdown("### ğŸ‘ï¸ ë¯¸ë¦¬ë³´ê¸°")
            bg_color_rgb = tuple(int(bg_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì›ë³¸**")
                st.image(first_frame_rgb, width="stretch")
            with col2:
                st.markdown("**ë°°ê²½ ì œê±° ì ìš©**")
                preview = process_single_frame(first_frame_rgb, bg_color_rgb, tolerance, edge_smoothing)
                checker = create_checker_background(preview.width, preview.height)
                checker.paste(preview, (0, 0), preview)
                st.image(checker, width="stretch")

            if st.button("âœ¨ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ìƒì„±", type="primary", width="stretch", key="video_convert"):
                with st.spinner("ë³€í™˜ ì¤‘..."):
                    processed_images, _ = process_video_to_sprites(
                        st.session_state.generated_video_path,
                        bg_color_rgb, tolerance, edge_smoothing,
                        frame_interval, max_frames, use_custom_size,
                        output_width, output_height, []
                    )
                    st.session_state.processed_images = processed_images
                    st.session_state.gif_speed = gif_speed
                    st.session_state.current_step = 3
                    st.rerun()

# ===== ê²°ê³¼ë¬¼ í‘œì‹œ =====
if st.session_state.processed_images:
    st.markdown("---")
    st.header("ğŸ“¦ ê²°ê³¼ë¬¼")

    processed_pil_images = st.session_state.processed_images
    current_gif_speed = st.session_state.get('gif_speed', 100)

    tab1, tab2, tab3 = st.tabs(["ğŸ¬ GIF", "ğŸ“„ ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸", "ğŸ–¼ï¸ í”„ë ˆì„ ì„ íƒ"])

    with tab1:
        # RGBA ì´ë¯¸ì§€ë¥¼ íˆ¬ëª… ë°°ê²½ GIFë¡œ ì˜¬ë°”ë¥´ê²Œ ë³€í™˜
        gif_buffer = io.BytesIO()
        converted_frames = []
        for frame in processed_pil_images:
            if frame.mode == 'RGBA':
                # íˆ¬ëª… ì˜ì—­ì„ ë§ˆì  íƒ€(255, 0, 255)ë¡œ ì±„ì›€ (íˆ¬ëª… ë§ˆì»¤)
                background = Image.new('RGBA', frame.size, (255, 0, 255, 255))
                composite = Image.alpha_composite(background, frame)
                p_frame = composite.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=255)
                # íˆ¬ëª… ìƒ‰ìƒ ì¸ë±ìŠ¤ ì°¾ê¸°
                palette = p_frame.getpalette()
                trans_index = 0
                for i in range(256):
                    if palette[i*3:i*3+3] == [255, 0, 255]:
                        trans_index = i
                        break
                converted_frames.append((p_frame, trans_index))
            else:
                converted_frames.append((frame.convert('P', palette=Image.ADAPTIVE, colors=256), None))

        if converted_frames:
            first_frame, first_trans = converted_frames[0]
            append_frames = [f[0] for f in converted_frames[1:]]
            first_frame.save(
                gif_buffer, format="GIF", save_all=True,
                append_images=append_frames,
                duration=current_gif_speed, loop=0, disposal=2,
                transparency=first_trans if first_trans is not None else 0
            )

        st.image(gif_buffer.getvalue(), caption="íˆ¬ëª… ë°°ê²½ GIF")

        # APNGë„ ìƒì„± (ì™„ë²½í•œ íˆ¬ëª…ë„ ì§€ì›)
        apng_buffer = io.BytesIO()
        processed_pil_images[0].save(
            apng_buffer, format="PNG", save_all=True,
            append_images=processed_pil_images[1:],
            duration=current_gif_speed, loop=0
        )

        dl_col1, dl_col2 = st.columns(2)
        with dl_col1:
            st.download_button("ğŸ¬ GIF ë‹¤ìš´ë¡œë“œ", gif_buffer.getvalue(), "animation.gif", "image/gif", width="stretch")
        with dl_col2:
            st.download_button("ğŸ–¼ï¸ APNG ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)", apng_buffer.getvalue(), "animation.png", "image/png", width="stretch",
                              help="APNGëŠ” ì™„ë²½í•œ íˆ¬ëª…ë„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.")

    with tab2:
        sheet_cols = st.number_input("ì—´ ìˆ˜ (0=ê°€ë¡œ í•œ ì¤„)", 0, len(processed_pil_images), 0)
        sprite_sheet = create_sprite_sheet(processed_pil_images, sheet_cols)
        sheet_buffer = io.BytesIO()
        sprite_sheet.save(sheet_buffer, format="PNG")
        st.image(sprite_sheet, caption=f"ìŠ¤í”„ë¼ì´íŠ¸ ì‹œíŠ¸ ({sprite_sheet.width}x{sprite_sheet.height})")

        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“„ PNG ì €ì¥", sheet_buffer.getvalue(), "sprite_sheet.png", "image/png", width="stretch")
        with col2:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for idx, img in enumerate(processed_pil_images):
                    img_arr = io.BytesIO()
                    img.save(img_arr, format="PNG")
                    zf.writestr(f"frame_{idx:03d}.png", img_arr.getvalue())
            st.download_button("ğŸ“¦ ZIP ì €ì¥", zip_buffer.getvalue(), "frames.zip", "application/zip", width="stretch")

    with tab3:
        if 'selected_frames' not in st.session_state:
            st.session_state.selected_frames = list(range(len(processed_pil_images)))

        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì „ì²´ ì„ íƒ", width="stretch"):
                st.session_state.selected_frames = list(range(len(processed_pil_images)))
                st.rerun()
        with col2:
            if st.button("âŒ ì „ì²´ í•´ì œ", width="stretch"):
                st.session_state.selected_frames = []
                st.rerun()

        cols_per_row = 6
        for row_start in range(0, len(processed_pil_images), cols_per_row):
            cols = st.columns(cols_per_row)
            for col_idx, img_idx in enumerate(range(row_start, min(row_start + cols_per_row, len(processed_pil_images)))):
                with cols[col_idx]:
                    is_sel = img_idx in st.session_state.selected_frames
                    if st.checkbox(f"#{img_idx+1}", value=is_sel, key=f"sel_{img_idx}"):
                        if img_idx not in st.session_state.selected_frames:
                            st.session_state.selected_frames.append(img_idx)
                    else:
                        if img_idx in st.session_state.selected_frames:
                            st.session_state.selected_frames.remove(img_idx)
                    thumb = processed_pil_images[img_idx].copy()
                    thumb.thumbnail((80, 80))
                    st.image(thumb)

        if st.session_state.selected_frames:
            st.info(f"ì„ íƒ: {len(st.session_state.selected_frames)}ê°œ")
            selected_imgs = [processed_pil_images[i] for i in sorted(st.session_state.selected_frames)]
            custom_cols = st.number_input("ì—´ ìˆ˜", 0, len(selected_imgs), 0, key="custom_cols")
            custom_sheet = create_sprite_sheet(selected_imgs, custom_cols)
            custom_buf = io.BytesIO()
            custom_sheet.save(custom_buf, format="PNG")
            st.image(custom_sheet)
            st.download_button("ğŸ“„ ì„ íƒ í”„ë ˆì„ ì €ì¥", custom_buf.getvalue(), "custom_sheet.png", "image/png", width="stretch")

    # ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°
    st.markdown("---")
    if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°", width="stretch"):
        st.session_state.current_step = 1
        st.session_state.uploaded_image = None
        st.session_state.generated_video_path = None
        st.session_state.processed_images = []
        st.session_state.selected_frames = []
        st.rerun()
